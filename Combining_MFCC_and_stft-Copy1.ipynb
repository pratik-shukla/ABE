{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FRsHwWQvpHFi"
   },
   "source": [
    "1. Load dataset\n",
    "2. Trim audio signals to small duration, label and store\n",
    "3. Make narrowband signals (x_train)\n",
    "4. Find mfcc features of wideband (y_train)\n",
    "5. DNN model -> predict mfcc\n",
    "6. MFCC -> audio signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E1JmNAUpES_4",
    "outputId": "4c9d941e-605c-4512-8f55-a92c141c9a43"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "RpCvIe4jc-aW"
   },
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "from IPython.display import Audio, display\n",
    "import os\n",
    "import scipy.signal as signal\n",
    "from scipy.signal import decimate\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import shutil\n",
    "import librosa\n",
    "import sklearn\n",
    "from scipy.signal import butter,filtfilt\n",
    "\n",
    "from pesq import pesq\n",
    "from pystoi import stoi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU, using /device:CPU:0.\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if len(device_name) > 0:\n",
    "    print(\"Found GPU at: {}\".format(device_name))\n",
    "else:\n",
    "    device_name = \"/device:CPU:0\"\n",
    "    print(\"No GPU, using {}.\".format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "IxFe2BZH1NLO"
   },
   "outputs": [],
   "source": [
    "#data, fs = librosa.load('/home/user/desktop/BTP_Pratik_Lovish/wav/03b03Tc.wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "1wY1VF2c1dAV"
   },
   "outputs": [],
   "source": [
    "#print(data, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "8s6ubMzv1nwm"
   },
   "outputs": [],
   "source": [
    "sound_file='/home/user/Desktop/BTP_Pratik_Lovish/wav/03b03Tc.wav'\n",
    "#display(Audio(sound_file, autoplay=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "KsaI6hRPEqC6"
   },
   "outputs": [],
   "source": [
    "# downsample all audio to 4khz bandwidth (8khz sampling freq)\n",
    "fs_new = 8000  # New sample rate\n",
    "destination_folder = '/home/user/Desktop/BTP_Pratik_Lovish/4khz_bandwidth_wav'\n",
    "\n",
    "\n",
    "# for i in file_names:\n",
    "#   fs, data = wavfile.read('/content/drive/MyDrive/wav/'+i)\n",
    "#   data_downsampled= signal.resample(data, int(len(data) * fs_new / fs))\n",
    "#   # Save the downsampled signal to a new WAV file\n",
    "#   new_filename=\"downsampled_\"+i\n",
    "#   wavfile.write(new_filename, fs_new, data_downsampled)\n",
    "\n",
    "#   # move file to drive \n",
    "#   source_file = '/content/'+new_filename\n",
    "#   shutil.move(source_file, destination_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "hzVrUJg0u61h"
   },
   "outputs": [],
   "source": [
    "cutoff=4100\n",
    "nyq=8000\n",
    "order=6\n",
    "fs=16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "ZvPPZx9GutCp"
   },
   "outputs": [],
   "source": [
    "#Function for lowpass filter\n",
    "def butter_lowpass_filter(data, cutoff, fs, order):\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    # Get the filter coefficients \n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S6sLd3kbRS0i"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "DCzonJhoXwta"
   },
   "outputs": [],
   "source": [
    "cnt={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hFtld_6MRUcJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jUwEAu8fyBe"
   },
   "source": [
    "Take audio path -> break it into \"s\" seconds audio ( if less than second rem then pad ) -> return array of data of \"s\" second data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "6QmpmolC8RHF"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "frame_size=512#2048  #512\n",
    "hop_length=frame_size//2#512 #256\n",
    "mfccs=100\n",
    "audio_framesx=[] # each frame has mfcc+ stft info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "hVklEtUT1adU"
   },
   "outputs": [],
   "source": [
    "def chunk(path,fs,dur):\n",
    "  arr, fs=librosa.load(path,sr=None) \n",
    "  aud_chunks=[]\n",
    "  sample_per_frame=int(fs*dur)\n",
    "\n",
    "  #print(sample_per_frame)\n",
    "  cnt_chunks=len(arr)//sample_per_frame\n",
    "  rem=len(arr)%sample_per_frame\n",
    "  arr=np.append(arr,np.zeros(sample_per_frame-rem))\n",
    "\n",
    "  if rem:\n",
    "    cnt_chunks+=1\n",
    "\n",
    "  for i in range(cnt_chunks):\n",
    "    frame=[]\n",
    "    for j in range(sample_per_frame):\n",
    "      frame.append(arr[i*sample_per_frame+j])\n",
    "    aud_chunks.append(frame)\n",
    "  \n",
    "  return aud_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "vSuPLAVBYjrF"
   },
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "from scipy.signal import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "pS5ufGyF8KP5"
   },
   "outputs": [],
   "source": [
    "def create_dataset(atekhz):\n",
    "  #x, sr1 = librosa.load(atekhz)\n",
    "  #x=x[:min_len]\n",
    "\n",
    "#   audio_x=chunk(atekhz, fs,0.5)\n",
    "#   for xarr in audio_x:\n",
    "    x, f=librosa.load(atekhz)\n",
    "    lowed_signal=butter_lowpass_filter(x, cutoff, fs, order)\n",
    "    #xx=librosa.feature.mfcc(y=lowed_signal, sr=fs//2, n_fft=frame_size, hop_length=hop_length, n_mfcc=mfccs)\n",
    "\n",
    "\n",
    "    mf=librosa.feature.mfcc(y=lowed_signal, sr=fs//2, n_fft=frame_size, hop_length=hop_length, n_mfcc=mfccs)\n",
    "\n",
    "    # delta_mfccs = librosa.feature.delta(mf)\n",
    "    # delta2_mfccs = librosa.feature.delta(mf, order=2)\n",
    "    #xx = np.hstack((mf, delta_mfccs, delta2_mfccs))\n",
    "    #print(mf.shape, delta_mfccs.shape, delta2_mfccs.shape, xx.shape)\n",
    "    xstft = np.abs(librosa.stft(lowed_signal,n_fft=frame_size, hop_length=hop_length))\n",
    "    #print(xstft.shape)\n",
    "    xframewise=[]\n",
    "\n",
    "    for j in range(len(mf[0])):\n",
    "      z=[]\n",
    "      for i in range(len(mf)):\n",
    "        z.append(mf[i][j])\n",
    "      # for i in range(len(mf)):\n",
    "      #   z.append(delta_mfccs[i][j])\n",
    "      # for i in range(len(mf)):\n",
    "      #   z.append(delta2_mfccs[i][j])\n",
    "      XXm.append(z)\n",
    "\n",
    "    for j in range(len(xstft[0])):\n",
    "      z=[]\n",
    "      for i in range(len(xstft)):\n",
    "        z.append(xstft[i][j])\n",
    "      XXs.append(z)\n",
    "\n",
    "    y=np.abs(librosa.stft(x,n_fft=frame_size, hop_length=hop_length))\n",
    "    for j in range(len(y[0])):\n",
    "      z=[]\n",
    "      for i in range(len(y)):\n",
    "        z.append(y[i][j])\n",
    "      YY.append(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "HsnGgQbtxZFO"
   },
   "outputs": [],
   "source": [
    "#create_dataset('/content/drive/MyDrive/wav/03a01Fa.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "IFQtsNKUJFdb"
   },
   "outputs": [],
   "source": [
    "XXs=[]\n",
    "XXm=[]\n",
    "YY=[]\n",
    "\n",
    "folder_path = '/home/user/Desktop/BTP_Pratik_Lovish/wav'\n",
    "file_names = os.listdir(folder_path)\n",
    "\n",
    "target_folder=r'/home/user/Desktop/BTP_Pratik_Lovish/timit-20230118T185105Z-001/timit'\n",
    "drfolders=os.listdir(target_folder)\n",
    "\n",
    "\n",
    "for f in file_names:\n",
    "    atekhz=folder_path+'/'+f\n",
    "    create_dataset(atekhz)\n",
    "\n",
    "#timit \n",
    "\n",
    "for folders in drfolders:\n",
    "  allfiles=os.listdir(target_folder+'/'+folders)\n",
    "  for files in allfiles:\n",
    "    if files.endswith('.wav'):\n",
    "        atekhz=target_folder+'/'+folders+'/'+files\n",
    "        create_dataset(atekhz)\n",
    "\n",
    "folders=[ 'Speech']\n",
    "prepath='/home/user/Desktop/BTP_Pratik_Lovish/speech/'\n",
    "for f in folders:\n",
    "  ifolders=os.listdir(prepath+str(f))\n",
    "  for ifolder in ifolders:\n",
    "    if not ifolder.endswith('README'):\n",
    "      files=os.listdir(prepath+str(f)+'/'+str(ifolder))\n",
    "      for fil in files:\n",
    "        if fil.endswith('.wav'):\n",
    "          atekhz=prepath+str(f)+'/'+str(ifolder)+'/'+str(fil)\n",
    "          if len(XXs)>800000:\n",
    "            break\n",
    "          create_dataset(atekhz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "qpO58eZ98wZo"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Splitting the dataset\n",
    "Xs_train, Xs_test, Xm_train,Xm_test, y_train, y_test = sklearn.model_selection.train_test_split(XXs, XXm, YY, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "yHEYYa2y0DyC"
   },
   "outputs": [],
   "source": [
    "Xs_train=np.array(Xs_train)\n",
    "Xs_test=np.array(Xs_test)\n",
    "Xm_train=np.array(Xm_train)\n",
    "Xm_test=np.array(Xm_test)\n",
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "DiMy7VYDQfjz"
   },
   "outputs": [],
   "source": [
    "modelm = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1024,activation=\"relu\", input_shape=Xm_train[0].shape),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu')\n",
    "])\n",
    "\n",
    "# Define the second neural network\n",
    "models = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1024,activation=\"relu\", input_shape=Xs_train[0].shape),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu')\n",
    "])\n",
    "\n",
    "# Concatenate the two models\n",
    "concatenated = tf.keras.layers.Concatenate()([modelm.output, models.output])\n",
    "dense_layer1 = tf.keras.layers.Dense(512, activation='relu')(concatenated)\n",
    "dense_layer2 = tf.keras.layers.Dense(256, activation='relu')(dense_layer1)\n",
    "output_layer = tf.keras.layers.Dense(units=int(y_train[0].shape[0]), activation=\"linear\")(dense_layer2)\n",
    "\n",
    "# Define the final model with the concatenated layers\n",
    "model = tf.keras.models.Model(inputs=[modelm.input, models.input], outputs=output_layer)\n",
    "model.compile(loss=tf.keras.losses.CosineSimilarity(axis=1), optimizer=\"adam\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ouiE-ng6xGjt",
    "outputId": "9c23aca5-54c1-4195-90f8-76d36951c932"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/650\n",
      "10322/10322 [==============================] - 150s 15ms/step - loss: -0.9996 - accuracy: 0.9902 - val_loss: -0.9979 - val_accuracy: 0.9820\n",
      "Epoch 2/650\n",
      "10322/10322 [==============================] - 146s 14ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9980 - val_accuracy: 0.9822\n",
      "Epoch 3/650\n",
      "10322/10322 [==============================] - 147s 14ms/step - loss: -0.9996 - accuracy: 0.9903 - val_loss: -0.9979 - val_accuracy: 0.9809\n",
      "Epoch 4/650\n",
      "10322/10322 [==============================] - 146s 14ms/step - loss: -0.9996 - accuracy: 0.9903 - val_loss: -0.9979 - val_accuracy: 0.9814\n",
      "Epoch 5/650\n",
      "10322/10322 [==============================] - 145s 14ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9980 - val_accuracy: 0.9819\n",
      "Epoch 6/650\n",
      "10322/10322 [==============================] - 145s 14ms/step - loss: -0.9996 - accuracy: 0.9903 - val_loss: -0.9979 - val_accuracy: 0.9815\n",
      "Epoch 7/650\n",
      "10322/10322 [==============================] - 149s 14ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9812\n",
      "Epoch 8/650\n",
      "10322/10322 [==============================] - 152s 15ms/step - loss: -0.9996 - accuracy: 0.9902 - val_loss: -0.9979 - val_accuracy: 0.9821\n",
      "Epoch 9/650\n",
      "10322/10322 [==============================] - 150s 15ms/step - loss: -0.9996 - accuracy: 0.9902 - val_loss: -0.9979 - val_accuracy: 0.9821\n",
      "Epoch 10/650\n",
      "10322/10322 [==============================] - 151s 15ms/step - loss: -0.9996 - accuracy: 0.9903 - val_loss: -0.9980 - val_accuracy: 0.9825\n",
      "Epoch 11/650\n",
      "10322/10322 [==============================] - 151s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9821\n",
      "Epoch 12/650\n",
      "10322/10322 [==============================] - 151s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9980 - val_accuracy: 0.9819\n",
      "Epoch 13/650\n",
      "10322/10322 [==============================] - 152s 15ms/step - loss: -0.9996 - accuracy: 0.9903 - val_loss: -0.9979 - val_accuracy: 0.9816\n",
      "Epoch 14/650\n",
      "10322/10322 [==============================] - 153s 15ms/step - loss: -0.9996 - accuracy: 0.9903 - val_loss: -0.9979 - val_accuracy: 0.9812\n",
      "Epoch 15/650\n",
      "10322/10322 [==============================] - 153s 15ms/step - loss: -0.9996 - accuracy: 0.9903 - val_loss: -0.9979 - val_accuracy: 0.9821\n",
      "Epoch 16/650\n",
      "10322/10322 [==============================] - 153s 15ms/step - loss: -0.9996 - accuracy: 0.9902 - val_loss: -0.9979 - val_accuracy: 0.9814\n",
      "Epoch 17/650\n",
      "10322/10322 [==============================] - 153s 15ms/step - loss: -0.9996 - accuracy: 0.9902 - val_loss: -0.9979 - val_accuracy: 0.9797\n",
      "Epoch 18/650\n",
      "10322/10322 [==============================] - 154s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9815\n",
      "Epoch 19/650\n",
      "10322/10322 [==============================] - 155s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9978 - val_accuracy: 0.9811\n",
      "Epoch 20/650\n",
      "10322/10322 [==============================] - 160s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9818\n",
      "Epoch 21/650\n",
      "10322/10322 [==============================] - 156s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9980 - val_accuracy: 0.9828\n",
      "Epoch 22/650\n",
      "10322/10322 [==============================] - 156s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9980 - val_accuracy: 0.9819\n",
      "Epoch 23/650\n",
      "10322/10322 [==============================] - 156s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9821\n",
      "Epoch 24/650\n",
      "10322/10322 [==============================] - 156s 15ms/step - loss: -0.9996 - accuracy: 0.9903 - val_loss: -0.9979 - val_accuracy: 0.9803\n",
      "Epoch 25/650\n",
      "10322/10322 [==============================] - 156s 15ms/step - loss: -0.9996 - accuracy: 0.9903 - val_loss: -0.9980 - val_accuracy: 0.9825\n",
      "Epoch 26/650\n",
      "10322/10322 [==============================] - 154s 15ms/step - loss: -0.9996 - accuracy: 0.9903 - val_loss: -0.9979 - val_accuracy: 0.9811\n",
      "Epoch 27/650\n",
      "10322/10322 [==============================] - 152s 15ms/step - loss: -0.9996 - accuracy: 0.9902 - val_loss: -0.9979 - val_accuracy: 0.9820\n",
      "Epoch 28/650\n",
      "10322/10322 [==============================] - 149s 14ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9829\n",
      "Epoch 29/650\n",
      "10322/10322 [==============================] - 153s 15ms/step - loss: -0.9996 - accuracy: 0.9903 - val_loss: -0.9979 - val_accuracy: 0.9818\n",
      "Epoch 30/650\n",
      "10322/10322 [==============================] - 153s 15ms/step - loss: -0.9996 - accuracy: 0.9903 - val_loss: -0.9980 - val_accuracy: 0.9831\n",
      "Epoch 31/650\n",
      "10322/10322 [==============================] - 150s 15ms/step - loss: -0.9996 - accuracy: 0.9902 - val_loss: -0.9979 - val_accuracy: 0.9802\n",
      "Epoch 32/650\n",
      "10322/10322 [==============================] - 152s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9813\n",
      "Epoch 33/650\n",
      "10322/10322 [==============================] - 156s 15ms/step - loss: -0.9996 - accuracy: 0.9903 - val_loss: -0.9979 - val_accuracy: 0.9818\n",
      "Epoch 34/650\n",
      "10322/10322 [==============================] - 159s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9818\n",
      "Epoch 35/650\n",
      "10322/10322 [==============================] - 158s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9980 - val_accuracy: 0.9828\n",
      "Epoch 36/650\n",
      "10322/10322 [==============================] - 159s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9806\n",
      "Epoch 37/650\n",
      "10322/10322 [==============================] - 159s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9820\n",
      "Epoch 38/650\n",
      "10322/10322 [==============================] - 159s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9823\n",
      "Epoch 39/650\n",
      "10322/10322 [==============================] - 158s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9812\n",
      "Epoch 40/650\n",
      "10322/10322 [==============================] - 158s 15ms/step - loss: -0.9996 - accuracy: 0.9903 - val_loss: -0.9979 - val_accuracy: 0.9820\n",
      "Epoch 41/650\n",
      "10322/10322 [==============================] - 157s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9820\n",
      "Epoch 42/650\n",
      "10322/10322 [==============================] - 160s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9821\n",
      "Epoch 43/650\n",
      "10322/10322 [==============================] - 161s 16ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9820\n",
      "Epoch 44/650\n",
      "10322/10322 [==============================] - 159s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9824\n",
      "Epoch 45/650\n",
      "10322/10322 [==============================] - 158s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9822\n",
      "Epoch 46/650\n",
      "10322/10322 [==============================] - 159s 15ms/step - loss: -0.9996 - accuracy: 0.9903 - val_loss: -0.9979 - val_accuracy: 0.9823\n",
      "Epoch 47/650\n",
      "10322/10322 [==============================] - 157s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9820\n",
      "Epoch 48/650\n",
      "10322/10322 [==============================] - 156s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9820\n",
      "Epoch 49/650\n",
      "10322/10322 [==============================] - 156s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9813\n",
      "Epoch 50/650\n",
      "10322/10322 [==============================] - 156s 15ms/step - loss: -0.9996 - accuracy: 0.9903 - val_loss: -0.9979 - val_accuracy: 0.9813\n",
      "Epoch 51/650\n",
      "10322/10322 [==============================] - 156s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9817\n",
      "Epoch 52/650\n",
      "10322/10322 [==============================] - 157s 15ms/step - loss: -0.9996 - accuracy: 0.9903 - val_loss: -0.9980 - val_accuracy: 0.9818\n",
      "Epoch 53/650\n",
      "10322/10322 [==============================] - 159s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9816\n",
      "Epoch 54/650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10322/10322 [==============================] - 157s 15ms/step - loss: -0.9996 - accuracy: 0.9903 - val_loss: -0.9979 - val_accuracy: 0.9818\n",
      "Epoch 55/650\n",
      "10322/10322 [==============================] - 155s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9815\n",
      "Epoch 56/650\n",
      "10322/10322 [==============================] - 158s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9811\n",
      "Epoch 57/650\n",
      "10322/10322 [==============================] - 157s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9812\n",
      "Epoch 58/650\n",
      "10322/10322 [==============================] - 158s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9826\n",
      "Epoch 59/650\n",
      "10322/10322 [==============================] - 160s 15ms/step - loss: -0.9996 - accuracy: 0.9903 - val_loss: -0.9980 - val_accuracy: 0.9827\n",
      "Epoch 60/650\n",
      "10322/10322 [==============================] - 161s 16ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9817\n",
      "Epoch 61/650\n",
      "10322/10322 [==============================] - 161s 16ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9805\n",
      "Epoch 62/650\n",
      "10322/10322 [==============================] - 160s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9813\n",
      "Epoch 63/650\n",
      "10322/10322 [==============================] - 158s 15ms/step - loss: -0.9996 - accuracy: 0.9903 - val_loss: -0.9979 - val_accuracy: 0.9818\n",
      "Epoch 64/650\n",
      "10322/10322 [==============================] - 158s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9814\n",
      "Epoch 65/650\n",
      "10322/10322 [==============================] - 159s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9811\n",
      "Epoch 66/650\n",
      "10322/10322 [==============================] - 159s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9980 - val_accuracy: 0.9823\n",
      "Epoch 67/650\n",
      "10322/10322 [==============================] - 160s 16ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9819\n",
      "Epoch 68/650\n",
      "10322/10322 [==============================] - 158s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9805\n",
      "Epoch 69/650\n",
      "10322/10322 [==============================] - 158s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9821\n",
      "Epoch 70/650\n",
      "10322/10322 [==============================] - 158s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9814\n",
      "Epoch 71/650\n",
      "10322/10322 [==============================] - 157s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9815\n",
      "Epoch 72/650\n",
      "10322/10322 [==============================] - 158s 15ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9816\n",
      "Epoch 73/650\n",
      "10322/10322 [==============================] - 156s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9818\n",
      "Epoch 74/650\n",
      "10322/10322 [==============================] - 155s 15ms/step - loss: -0.9996 - accuracy: 0.9903 - val_loss: -0.9979 - val_accuracy: 0.9822\n",
      "Epoch 75/650\n",
      "10322/10322 [==============================] - 157s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9820\n",
      "Epoch 76/650\n",
      "10322/10322 [==============================] - 157s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9816\n",
      "Epoch 77/650\n",
      "10322/10322 [==============================] - 158s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9820\n",
      "Epoch 78/650\n",
      "10322/10322 [==============================] - 159s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9824\n",
      "Epoch 79/650\n",
      "10322/10322 [==============================] - 158s 15ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9980 - val_accuracy: 0.9818\n",
      "Epoch 80/650\n",
      "10322/10322 [==============================] - 156s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9810\n",
      "Epoch 81/650\n",
      "10322/10322 [==============================] - 155s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9817\n",
      "Epoch 82/650\n",
      "10322/10322 [==============================] - 153s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9817\n",
      "Epoch 83/650\n",
      "10322/10322 [==============================] - 154s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9980 - val_accuracy: 0.9828\n",
      "Epoch 84/650\n",
      "10322/10322 [==============================] - 155s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9980 - val_accuracy: 0.9821\n",
      "Epoch 85/650\n",
      "10322/10322 [==============================] - 155s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9808\n",
      "Epoch 86/650\n",
      "10322/10322 [==============================] - 155s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9814\n",
      "Epoch 87/650\n",
      "10322/10322 [==============================] - 155s 15ms/step - loss: -0.9996 - accuracy: 0.9903 - val_loss: -0.9979 - val_accuracy: 0.9816\n",
      "Epoch 88/650\n",
      "10322/10322 [==============================] - 154s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9824\n",
      "Epoch 89/650\n",
      "10322/10322 [==============================] - 156s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9810\n",
      "Epoch 90/650\n",
      "10322/10322 [==============================] - 154s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9821\n",
      "Epoch 91/650\n",
      "10322/10322 [==============================] - 155s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9819\n",
      "Epoch 92/650\n",
      "10322/10322 [==============================] - 157s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9816\n",
      "Epoch 93/650\n",
      "10322/10322 [==============================] - 155s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9822\n",
      "Epoch 94/650\n",
      "10322/10322 [==============================] - 156s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9978 - val_accuracy: 0.9810\n",
      "Epoch 95/650\n",
      "10322/10322 [==============================] - 156s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9810\n",
      "Epoch 96/650\n",
      "10322/10322 [==============================] - 159s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9821\n",
      "Epoch 97/650\n",
      "10322/10322 [==============================] - 158s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9815\n",
      "Epoch 98/650\n",
      "10322/10322 [==============================] - 157s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9980 - val_accuracy: 0.9818\n",
      "Epoch 99/650\n",
      "10322/10322 [==============================] - 157s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9819\n",
      "Epoch 100/650\n",
      "10322/10322 [==============================] - 157s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9821\n",
      "Epoch 101/650\n",
      "10322/10322 [==============================] - 156s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9824\n",
      "Epoch 102/650\n",
      "10322/10322 [==============================] - 157s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9817\n",
      "Epoch 103/650\n",
      "10322/10322 [==============================] - 156s 15ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9814\n",
      "Epoch 104/650\n",
      "10322/10322 [==============================] - 156s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9812\n",
      "Epoch 105/650\n",
      "10322/10322 [==============================] - 157s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9814\n",
      "Epoch 106/650\n",
      "10322/10322 [==============================] - 154s 15ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9816\n",
      "Epoch 107/650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10322/10322 [==============================] - 154s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9818\n",
      "Epoch 108/650\n",
      "10322/10322 [==============================] - 153s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9822\n",
      "Epoch 109/650\n",
      "10322/10322 [==============================] - 153s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9820\n",
      "Epoch 110/650\n",
      "10322/10322 [==============================] - 151s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9812\n",
      "Epoch 111/650\n",
      "10322/10322 [==============================] - 153s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9815\n",
      "Epoch 112/650\n",
      "10322/10322 [==============================] - 153s 15ms/step - loss: -0.9996 - accuracy: 0.9903 - val_loss: -0.9979 - val_accuracy: 0.9827\n",
      "Epoch 113/650\n",
      "10322/10322 [==============================] - 155s 15ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9820\n",
      "Epoch 114/650\n",
      "10322/10322 [==============================] - 157s 15ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9980 - val_accuracy: 0.9822\n",
      "Epoch 115/650\n",
      "10322/10322 [==============================] - 156s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9814\n",
      "Epoch 116/650\n",
      "10322/10322 [==============================] - 155s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9980 - val_accuracy: 0.9819\n",
      "Epoch 117/650\n",
      "10322/10322 [==============================] - 156s 15ms/step - loss: -0.9996 - accuracy: 0.9903 - val_loss: -0.9979 - val_accuracy: 0.9824\n",
      "Epoch 118/650\n",
      "10322/10322 [==============================] - 156s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9818\n",
      "Epoch 119/650\n",
      "10322/10322 [==============================] - 158s 15ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9829\n",
      "Epoch 120/650\n",
      "10322/10322 [==============================] - 157s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9821\n",
      "Epoch 121/650\n",
      "10322/10322 [==============================] - 156s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9818\n",
      "Epoch 122/650\n",
      "10322/10322 [==============================] - 156s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9817\n",
      "Epoch 123/650\n",
      "10322/10322 [==============================] - 156s 15ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9823\n",
      "Epoch 124/650\n",
      "10322/10322 [==============================] - 157s 15ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9814\n",
      "Epoch 125/650\n",
      "10322/10322 [==============================] - 154s 15ms/step - loss: -0.9996 - accuracy: 0.9903 - val_loss: -0.9979 - val_accuracy: 0.9828\n",
      "Epoch 126/650\n",
      "10322/10322 [==============================] - 155s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9807\n",
      "Epoch 127/650\n",
      "10322/10322 [==============================] - 155s 15ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9820\n",
      "Epoch 128/650\n",
      "10322/10322 [==============================] - 154s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9819\n",
      "Epoch 129/650\n",
      "10322/10322 [==============================] - 155s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9822\n",
      "Epoch 130/650\n",
      "10322/10322 [==============================] - 156s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9813\n",
      "Epoch 131/650\n",
      "10322/10322 [==============================] - 156s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9816\n",
      "Epoch 132/650\n",
      "10322/10322 [==============================] - 155s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9820\n",
      "Epoch 133/650\n",
      "10322/10322 [==============================] - 156s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9814\n",
      "Epoch 134/650\n",
      "10322/10322 [==============================] - 157s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9808\n",
      "Epoch 135/650\n",
      "10322/10322 [==============================] - 156s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9809\n",
      "Epoch 136/650\n",
      "10322/10322 [==============================] - 157s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9980 - val_accuracy: 0.9821\n",
      "Epoch 137/650\n",
      "10322/10322 [==============================] - 156s 15ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9828\n",
      "Epoch 138/650\n",
      "10322/10322 [==============================] - 155s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9823\n",
      "Epoch 139/650\n",
      "10322/10322 [==============================] - 155s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9823\n",
      "Epoch 140/650\n",
      "10322/10322 [==============================] - 155s 15ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9821\n",
      "Epoch 141/650\n",
      "10322/10322 [==============================] - 154s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9818\n",
      "Epoch 142/650\n",
      "10322/10322 [==============================] - 154s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9823\n",
      "Epoch 143/650\n",
      "10322/10322 [==============================] - 154s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9819\n",
      "Epoch 144/650\n",
      "10322/10322 [==============================] - 153s 15ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9806\n",
      "Epoch 145/650\n",
      "10322/10322 [==============================] - 156s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9816\n",
      "Epoch 146/650\n",
      "10322/10322 [==============================] - 155s 15ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9822\n",
      "Epoch 147/650\n",
      "10322/10322 [==============================] - 157s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9823\n",
      "Epoch 148/650\n",
      "10322/10322 [==============================] - 157s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9980 - val_accuracy: 0.9818\n",
      "Epoch 149/650\n",
      "10322/10322 [==============================] - 160s 15ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9816\n",
      "Epoch 150/650\n",
      "10322/10322 [==============================] - 161s 16ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9806\n",
      "Epoch 151/650\n",
      "10322/10322 [==============================] - 160s 15ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9811\n",
      "Epoch 152/650\n",
      "10322/10322 [==============================] - 159s 15ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9816\n",
      "Epoch 153/650\n",
      "10322/10322 [==============================] - 153s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9818\n",
      "Epoch 154/650\n",
      "10322/10322 [==============================] - 153s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9824\n",
      "Epoch 155/650\n",
      "10322/10322 [==============================] - 154s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9818\n",
      "Epoch 156/650\n",
      "10322/10322 [==============================] - 154s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9800\n",
      "Epoch 157/650\n",
      "10322/10322 [==============================] - 153s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9817\n",
      "Epoch 158/650\n",
      "10322/10322 [==============================] - 151s 15ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9822\n",
      "Epoch 159/650\n",
      "10322/10322 [==============================] - 150s 15ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9817\n",
      "Epoch 160/650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10322/10322 [==============================] - 150s 15ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9825\n",
      "Epoch 161/650\n",
      "10322/10322 [==============================] - 150s 15ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9816\n",
      "Epoch 162/650\n",
      "10322/10322 [==============================] - 151s 15ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9814\n",
      "Epoch 163/650\n",
      "10322/10322 [==============================] - 150s 15ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9816\n",
      "Epoch 164/650\n",
      "10322/10322 [==============================] - 151s 15ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9817\n",
      "Epoch 165/650\n",
      "10322/10322 [==============================] - 150s 15ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9816\n",
      "Epoch 166/650\n",
      "10322/10322 [==============================] - 151s 15ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9978 - val_accuracy: 0.9810\n",
      "Epoch 167/650\n",
      "10322/10322 [==============================] - 149s 14ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9809\n",
      "Epoch 168/650\n",
      "10322/10322 [==============================] - 147s 14ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9819\n",
      "Epoch 169/650\n",
      "10322/10322 [==============================] - 147s 14ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9823\n",
      "Epoch 170/650\n",
      "10322/10322 [==============================] - 152s 15ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9819\n",
      "Epoch 171/650\n",
      "10322/10322 [==============================] - 147s 14ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9819\n",
      "Epoch 172/650\n",
      "10322/10322 [==============================] - 150s 14ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9823\n",
      "Epoch 173/650\n",
      "10322/10322 [==============================] - 150s 15ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9819\n",
      "Epoch 174/650\n",
      "10322/10322 [==============================] - 149s 14ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9980 - val_accuracy: 0.9828\n",
      "Epoch 175/650\n",
      "10322/10322 [==============================] - 148s 14ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9819\n",
      "Epoch 176/650\n",
      "10322/10322 [==============================] - 148s 14ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9816\n",
      "Epoch 177/650\n",
      "10322/10322 [==============================] - 144s 14ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9828\n",
      "Epoch 178/650\n",
      "10322/10322 [==============================] - 145s 14ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9978 - val_accuracy: 0.9803\n",
      "Epoch 179/650\n",
      "10322/10322 [==============================] - 147s 14ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9821\n",
      "Epoch 180/650\n",
      "10322/10322 [==============================] - 148s 14ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9818\n",
      "Epoch 181/650\n",
      "10322/10322 [==============================] - 146s 14ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9817\n",
      "Epoch 182/650\n",
      "10322/10322 [==============================] - 147s 14ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9815\n",
      "Epoch 183/650\n",
      "10322/10322 [==============================] - 146s 14ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9813\n",
      "Epoch 184/650\n",
      "10322/10322 [==============================] - 146s 14ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9817\n",
      "Epoch 185/650\n",
      "10322/10322 [==============================] - 172s 17ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9818\n",
      "Epoch 186/650\n",
      "10322/10322 [==============================] - 274s 27ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9814\n",
      "Epoch 187/650\n",
      "10322/10322 [==============================] - 251s 24ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9814\n",
      "Epoch 188/650\n",
      "10322/10322 [==============================] - 244s 24ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9819\n",
      "Epoch 189/650\n",
      "10322/10322 [==============================] - 242s 23ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9823\n",
      "Epoch 190/650\n",
      "10322/10322 [==============================] - 239s 23ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9822\n",
      "Epoch 191/650\n",
      "10322/10322 [==============================] - 235s 23ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9815\n",
      "Epoch 192/650\n",
      "10322/10322 [==============================] - 235s 23ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9816\n",
      "Epoch 193/650\n",
      "10322/10322 [==============================] - 226s 22ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9817\n",
      "Epoch 194/650\n",
      "10322/10322 [==============================] - 227s 22ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9820\n",
      "Epoch 195/650\n",
      "10322/10322 [==============================] - 219s 21ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9818\n",
      "Epoch 196/650\n",
      "10322/10322 [==============================] - 217s 21ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9826\n",
      "Epoch 197/650\n",
      "10322/10322 [==============================] - 214s 21ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9814\n",
      "Epoch 198/650\n",
      "10322/10322 [==============================] - 212s 21ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9978 - val_accuracy: 0.9804\n",
      "Epoch 199/650\n",
      "10322/10322 [==============================] - 213s 21ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9819\n",
      "Epoch 200/650\n",
      "10322/10322 [==============================] - 213s 21ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9816\n",
      "Epoch 201/650\n",
      "10322/10322 [==============================] - 213s 21ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9817\n",
      "Epoch 202/650\n",
      "10322/10322 [==============================] - 213s 21ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9820\n",
      "Epoch 203/650\n",
      "10322/10322 [==============================] - 212s 21ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9814\n",
      "Epoch 204/650\n",
      "10322/10322 [==============================] - 212s 21ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9814\n",
      "Epoch 205/650\n",
      "10322/10322 [==============================] - 211s 20ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9825\n",
      "Epoch 206/650\n",
      "10322/10322 [==============================] - 212s 21ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9814\n",
      "Epoch 207/650\n",
      "10322/10322 [==============================] - 212s 21ms/step - loss: -0.9996 - accuracy: 0.9904 - val_loss: -0.9979 - val_accuracy: 0.9820\n",
      "Epoch 208/650\n",
      "10322/10322 [==============================] - 210s 20ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9818\n",
      "Epoch 209/650\n",
      "10322/10322 [==============================] - 211s 20ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9808\n",
      "Epoch 210/650\n",
      "10322/10322 [==============================] - 211s 20ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9826\n",
      "Epoch 211/650\n",
      "10322/10322 [==============================] - 213s 21ms/step - loss: -0.9996 - accuracy: 0.9908 - val_loss: -0.9979 - val_accuracy: 0.9820\n",
      "Epoch 212/650\n",
      "10322/10322 [==============================] - 213s 21ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9811\n",
      "Epoch 213/650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10322/10322 [==============================] - 213s 21ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9817\n",
      "Epoch 214/650\n",
      "10322/10322 [==============================] - 213s 21ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9808\n",
      "Epoch 215/650\n",
      "10322/10322 [==============================] - 214s 21ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9820\n",
      "Epoch 216/650\n",
      "10322/10322 [==============================] - 216s 21ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9813\n",
      "Epoch 217/650\n",
      "10322/10322 [==============================] - 219s 21ms/step - loss: -0.9996 - accuracy: 0.9908 - val_loss: -0.9979 - val_accuracy: 0.9818\n",
      "Epoch 218/650\n",
      "10322/10322 [==============================] - 218s 21ms/step - loss: -0.9996 - accuracy: 0.9908 - val_loss: -0.9979 - val_accuracy: 0.9806\n",
      "Epoch 219/650\n",
      "10322/10322 [==============================] - 218s 21ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9805\n",
      "Epoch 220/650\n",
      "10322/10322 [==============================] - 220s 21ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9826\n",
      "Epoch 221/650\n",
      "10322/10322 [==============================] - 217s 21ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9815\n",
      "Epoch 222/650\n",
      "10322/10322 [==============================] - 218s 21ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9978 - val_accuracy: 0.9820\n",
      "Epoch 223/650\n",
      "10322/10322 [==============================] - 217s 21ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9824\n",
      "Epoch 224/650\n",
      "10322/10322 [==============================] - 218s 21ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9980 - val_accuracy: 0.9823\n",
      "Epoch 225/650\n",
      "10322/10322 [==============================] - 218s 21ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9828\n",
      "Epoch 226/650\n",
      "10322/10322 [==============================] - 218s 21ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9815\n",
      "Epoch 227/650\n",
      "10322/10322 [==============================] - 220s 21ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9807\n",
      "Epoch 228/650\n",
      "10322/10322 [==============================] - 220s 21ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9820\n",
      "Epoch 229/650\n",
      "10322/10322 [==============================] - 219s 21ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9824\n",
      "Epoch 230/650\n",
      "10322/10322 [==============================] - 218s 21ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9821\n",
      "Epoch 231/650\n",
      "10322/10322 [==============================] - 217s 21ms/step - loss: -0.9996 - accuracy: 0.9905 - val_loss: -0.9979 - val_accuracy: 0.9824\n",
      "Epoch 232/650\n",
      "10322/10322 [==============================] - 217s 21ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9822\n",
      "Epoch 233/650\n",
      "10322/10322 [==============================] - 218s 21ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9815\n",
      "Epoch 234/650\n",
      "10322/10322 [==============================] - 217s 21ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9818\n",
      "Epoch 235/650\n",
      "10322/10322 [==============================] - 217s 21ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9807\n",
      "Epoch 236/650\n",
      "10322/10322 [==============================] - 217s 21ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9819\n",
      "Epoch 237/650\n",
      "10322/10322 [==============================] - 219s 21ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9811\n",
      "Epoch 238/650\n",
      "10322/10322 [==============================] - 217s 21ms/step - loss: -0.9996 - accuracy: 0.9908 - val_loss: -0.9978 - val_accuracy: 0.9813\n",
      "Epoch 239/650\n",
      "10322/10322 [==============================] - 217s 21ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9820\n",
      "Epoch 240/650\n",
      "10322/10322 [==============================] - 217s 21ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9823\n",
      "Epoch 241/650\n",
      "10322/10322 [==============================] - 219s 21ms/step - loss: -0.9996 - accuracy: 0.9909 - val_loss: -0.9979 - val_accuracy: 0.9814\n",
      "Epoch 242/650\n",
      "10322/10322 [==============================] - 219s 21ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9815\n",
      "Epoch 243/650\n",
      "10322/10322 [==============================] - 217s 21ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9821\n",
      "Epoch 244/650\n",
      "10322/10322 [==============================] - 218s 21ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9821\n",
      "Epoch 245/650\n",
      "10322/10322 [==============================] - 219s 21ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9816\n",
      "Epoch 246/650\n",
      "10322/10322 [==============================] - 219s 21ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9814\n",
      "Epoch 247/650\n",
      "10322/10322 [==============================] - 218s 21ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9811\n",
      "Epoch 248/650\n",
      "10322/10322 [==============================] - 174s 17ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9821\n",
      "Epoch 249/650\n",
      "10322/10322 [==============================] - 213s 21ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9814\n",
      "Epoch 250/650\n",
      "10322/10322 [==============================] - 212s 21ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9819\n",
      "Epoch 251/650\n",
      "10322/10322 [==============================] - 212s 21ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9824\n",
      "Epoch 252/650\n",
      "10322/10322 [==============================] - 212s 21ms/step - loss: -0.9996 - accuracy: 0.9908 - val_loss: -0.9979 - val_accuracy: 0.9814\n",
      "Epoch 253/650\n",
      "10322/10322 [==============================] - 212s 21ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9825\n",
      "Epoch 254/650\n",
      "10322/10322 [==============================] - 209s 20ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9823\n",
      "Epoch 255/650\n",
      "10322/10322 [==============================] - 212s 21ms/step - loss: -0.9996 - accuracy: 0.9908 - val_loss: -0.9979 - val_accuracy: 0.9820\n",
      "Epoch 256/650\n",
      "10322/10322 [==============================] - 210s 20ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9812\n",
      "Epoch 257/650\n",
      "10322/10322 [==============================] - 215s 21ms/step - loss: -0.9996 - accuracy: 0.9908 - val_loss: -0.9979 - val_accuracy: 0.9811\n",
      "Epoch 258/650\n",
      "10322/10322 [==============================] - 215s 21ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9815\n",
      "Epoch 259/650\n",
      "10322/10322 [==============================] - 214s 21ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9818\n",
      "Epoch 260/650\n",
      "10322/10322 [==============================] - 216s 21ms/step - loss: -0.9996 - accuracy: 0.9908 - val_loss: -0.9979 - val_accuracy: 0.9812\n",
      "Epoch 261/650\n",
      "10322/10322 [==============================] - 216s 21ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9819\n",
      "Epoch 262/650\n",
      "10322/10322 [==============================] - 218s 21ms/step - loss: -0.9996 - accuracy: 0.9908 - val_loss: -0.9975 - val_accuracy: 0.9748\n",
      "Epoch 263/650\n",
      "10322/10322 [==============================] - 214s 21ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9825\n",
      "Epoch 264/650\n",
      "10322/10322 [==============================] - 215s 21ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9816\n",
      "Epoch 265/650\n",
      "10322/10322 [==============================] - 213s 21ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9811\n",
      "Epoch 266/650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10322/10322 [==============================] - 213s 21ms/step - loss: -0.9996 - accuracy: 0.9908 - val_loss: -0.9980 - val_accuracy: 0.9820\n",
      "Epoch 267/650\n",
      "10322/10322 [==============================] - 214s 21ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9815\n",
      "Epoch 268/650\n",
      "10322/10322 [==============================] - 212s 21ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9819\n",
      "Epoch 269/650\n",
      "10322/10322 [==============================] - 213s 21ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9821\n",
      "Epoch 270/650\n",
      "10322/10322 [==============================] - 213s 21ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9815\n",
      "Epoch 271/650\n",
      "10322/10322 [==============================] - 213s 21ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9980 - val_accuracy: 0.9824\n",
      "Epoch 272/650\n",
      "10322/10322 [==============================] - 213s 21ms/step - loss: -0.9996 - accuracy: 0.9908 - val_loss: -0.9980 - val_accuracy: 0.9823\n",
      "Epoch 273/650\n",
      "10322/10322 [==============================] - 215s 21ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9817\n",
      "Epoch 274/650\n",
      "10322/10322 [==============================] - 212s 21ms/step - loss: -0.9996 - accuracy: 0.9908 - val_loss: -0.9980 - val_accuracy: 0.9824\n",
      "Epoch 275/650\n",
      "10322/10322 [==============================] - 209s 20ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9823\n",
      "Epoch 276/650\n",
      "10322/10322 [==============================] - 212s 21ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9821\n",
      "Epoch 277/650\n",
      "10322/10322 [==============================] - 208s 20ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9816\n",
      "Epoch 278/650\n",
      "10322/10322 [==============================] - 197s 19ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9819\n",
      "Epoch 279/650\n",
      "10322/10322 [==============================] - 212s 21ms/step - loss: -0.9996 - accuracy: 0.9908 - val_loss: -0.9979 - val_accuracy: 0.9819\n",
      "Epoch 280/650\n",
      "10322/10322 [==============================] - 212s 21ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9980 - val_accuracy: 0.9821\n",
      "Epoch 281/650\n",
      "10322/10322 [==============================] - 211s 20ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9979 - val_accuracy: 0.9821\n",
      "Epoch 282/650\n",
      "10322/10322 [==============================] - 210s 20ms/step - loss: -0.9996 - accuracy: 0.9907 - val_loss: -0.9979 - val_accuracy: 0.9825\n",
      "Epoch 283/650\n",
      "10322/10322 [==============================] - 211s 20ms/step - loss: -0.9996 - accuracy: 0.9906 - val_loss: -0.9980 - val_accuracy: 0.9828\n",
      "Epoch 284/650\n",
      " 4841/10322 [=============>................] - ETA: 1:41 - loss: -0.9996 - accuracy: 0.9907"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-a874828cab61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mXm_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXs_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m650\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mXm_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXs_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit([Xm_train, Xs_train], y_train, epochs=650, batch_size=64, validation_data=([Xm_test, Xs_test], y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "DtI4xH48_qa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dense_9_input (InputLayer)      [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_12_input (InputLayer)     [(None, 257)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1024)         103424      dense_9_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1024)         264192      dense_12_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 512)          524800      dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 512)          524800      dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 256)          131328      dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 256)          131328      dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           dense_11[0][0]                   \n",
      "                                                                 dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 512)          262656      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 256)          131328      dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 257)          66049       dense_16[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,139,905\n",
      "Trainable params: 2,139,905\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#new_model = tf.keras.models.load_model('my_model')\n",
    "\n",
    "# Check its architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "LjrHj7OAcGlQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5161/5161 [==============================] - 29s 6ms/step - loss: -0.9979 - accuracy: 0.9819\n",
      "Test accuracy: 0.9819493293762207\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc =model.evaluate([Xm_test, Xs_test], y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "WUza-hoCp__Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "f2HpxDCE9AT6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5792176723480225 0.9552507382952274\n",
      "4.151932716369629 0.9041473474579839\n",
      "4.068626403808594 0.9366355711334255\n",
      "3.7598180770874023 0.8901178914442606\n",
      "3.919708728790283 0.9750097457714274\n",
      "3.960050344467163 0.948584105676113\n",
      "3.7149009704589844 0.9182337528171773\n",
      "3.9563441276550293 0.9159336352573245\n",
      "3.8932154178619385 0.8991685626893383\n",
      "3.86728835105896 0.973284635190594\n",
      "4.007477283477783 0.9427825992234015\n",
      "3.88081431388855 0.9435469641470479\n",
      "4.102289199829102 0.9594019681332864\n",
      "3.7701401710510254 0.9429343078618789\n",
      "3.834510087966919 0.9336819855635158\n",
      "4.177086353302002 0.9364095184381709\n",
      "3.9010941982269287 0.928938307831639\n",
      "3.2129833698272705 0.920150943582608\n",
      "3.558336019515991 0.8355835467719119\n",
      "3.564776659011841 0.9509831809246408\n",
      "4.029563903808594 0.9357564192591676\n",
      "3.9794485569000244 0.8724554062368786\n",
      "3.862083911895752 0.9624843996541015\n",
      "4.079300880432129 0.955666802782591\n",
      "3.982614040374756 0.9180600661581807\n",
      "4.221593379974365 0.9176627583741953\n",
      "4.130198001861572 0.9319693976494418\n",
      "3.99579119682312 0.8828013512099752\n",
      "4.076071739196777 0.9065464287475495\n",
      "4.03297233581543 0.9622804451301434\n",
      "3.9318721294403076 0.8823803174067895\n",
      "3.3789188861846924 0.9332262361354728\n",
      "3.955916404724121 0.9015021573003631\n",
      "3.9846911430358887 0.9018214828620057\n",
      "3.7964279651641846 0.966597107194792\n",
      "4.03389310836792 0.9525925862092709\n",
      "3.8376426696777344 0.9376617609993725\n",
      "3.905333995819092 0.9084730243782712\n",
      "3.8905625343322754 0.9013985505413168\n",
      "3.59480619430542 0.8498506995714156\n",
      "4.05491828918457 0.9611073401229356\n",
      "4.134274959564209 0.9475517495948481\n",
      "3.7075467109680176 0.9598971974836621\n",
      "3.887261390686035 0.9498175941058852\n",
      "3.84330415725708 0.8659641638955965\n",
      "3.887418270111084 0.9350921410360297\n",
      "4.072172164916992 0.956602869926916\n",
      "3.8533499240875244 0.9587551506961048\n",
      "4.128632545471191 0.9435759269835139\n",
      "3.7801051139831543 0.9441114492075068\n",
      "4.043389797210693 0.955281330977615\n",
      "4.052670478820801 0.9689841429967647\n",
      "4.014595985412598 0.9149937398575128\n",
      "4.038658142089844 0.9299714058368648\n",
      "3.5956461429595947 0.957995899702917\n",
      "3.665313720703125 0.9071155270339681\n",
      "3.9183342456817627 0.8847665928708912\n",
      "4.089409828186035 0.9340140180714575\n",
      "4.017214298248291 0.9204383246345615\n",
      "3.9173765182495117 0.9035073765507369\n",
      "3.8909082412719727 0.94399627348968\n",
      "4.070199012756348 0.9414326561327955\n",
      "4.1156792640686035 0.8316487317934002\n",
      "4.036381721496582 0.9374790515835477\n",
      "3.4836411476135254 0.9195103520374598\n",
      "4.049219608306885 0.9663989419938693\n",
      "3.910888195037842 0.9494022154170201\n",
      "3.8546180725097656 0.9267904734744217\n",
      "3.729269504547119 0.935059293396963\n",
      "3.93316388130188 0.9173428555656041\n",
      "3.9729106426239014 0.9485272825803012\n",
      "3.6373825073242188 0.9306748754165959\n",
      "3.909991979598999 0.9302893129963294\n",
      "3.8054921627044678 0.9375336656803387\n",
      "3.840442657470703 0.9548129118956854\n",
      "4.154512405395508 0.9401385372822496\n",
      "3.968475103378296 0.9382698875429131\n",
      "4.023481845855713 0.9215507538230802\n",
      "4.048876762390137 0.9472688287045304\n",
      "4.2783050537109375 0.9514020107125221\n",
      "3.790069580078125 0.9602033488285558\n",
      "3.968844175338745 0.9631820357911944\n",
      "4.2319111824035645 0.9571144316774358\n",
      "3.8915047645568848 0.9351049513188552\n",
      "3.9373438358306885 0.8777637250545774\n",
      "4.12086296081543 0.9401016544264389\n",
      "4.137324333190918 0.8924508592125435\n",
      "3.9654860496520996 0.9039087644149727\n",
      "3.8680036067962646 0.9269682464404295\n",
      "3.8055405616760254 0.9375445221881971\n",
      "4.089385509490967 0.888466940343456\n",
      "3.7229840755462646 0.8972977361962031\n",
      "4.049733638763428 0.92180830076787\n",
      "3.9195566177368164 0.9117753842785422\n",
      "3.945148468017578 0.9139509480345661\n",
      "3.8659911155700684 0.9313349504737087\n",
      "4.044450759887695 0.948730214261011\n",
      "4.091607570648193 0.8860496795287761\n",
      "3.7967023849487305 0.9334553131184243\n",
      "3.9856526851654053 0.9482986036709545\n",
      "4.125406265258789 0.8787744422840901\n",
      "3.757666826248169 0.9484010186730666\n",
      "3.7737536430358887 0.9510434593551542\n",
      "4.068698883056641 0.954003028872322\n",
      "4.071952819824219 0.8540185580739402\n",
      "3.9803833961486816 0.9138456509857767\n",
      "3.805586814880371 0.8924746821921802\n",
      "3.9465572834014893 0.9475472885472591\n",
      "4.008533954620361 0.9621936149294542\n",
      "3.99295973777771 0.932343600518731\n",
      "3.603348970413208 0.9553768400580325\n",
      "3.9106435775756836 0.9123870116024162\n",
      "3.8336241245269775 0.9214144018285427\n",
      "3.865222692489624 0.9253775286119158\n",
      "3.9423575401306152 0.9115553766766648\n",
      "4.093844890594482 0.9214590092062613\n",
      "3.9318764209747314 0.9296219233299314\n",
      "3.9319727420806885 0.9321666747790825\n",
      "3.9621379375457764 0.9525537958762765\n",
      "4.104337215423584 0.9317897798211884\n",
      "3.784059524536133 0.9428969306569458\n",
      "4.1600165367126465 0.9270305955145105\n",
      "4.089951038360596 0.8880175740313301\n",
      "3.8729772567749023 0.9087301097754252\n",
      "3.996473550796509 0.9550113582818046\n",
      "4.021648406982422 0.8592231096971152\n",
      "3.6186604499816895 0.9540080034949235\n",
      "3.8735129833221436 0.9280141854986668\n",
      "3.770883083343506 0.9393946347626672\n",
      "3.9827115535736084 0.9266230828271862\n",
      "3.901832342147827 0.9125518191010441\n",
      "3.9529130458831787 0.9405863184827647\n",
      "3.7193470001220703 0.9659220383333827\n",
      "4.144654750823975 0.9373355615471202\n",
      "3.625140905380249 0.9341916010524598\n",
      "3.962486505508423 0.9350572577580077\n",
      "3.9049246311187744 0.9541837759656725\n",
      "4.004898548126221 0.9549396344513994\n",
      "3.507478713989258 0.9122181179234087\n",
      "4.222133636474609 0.9212493132249888\n",
      "4.160702228546143 0.8555400406151904\n",
      "3.971285820007324 0.917375001057719\n",
      "3.7794482707977295 0.9295805536552332\n",
      "4.261746883392334 0.9233638491954258\n",
      "3.9246551990509033 0.9562540627692313\n",
      "4.201936721801758 0.9425032774122387\n",
      "3.1871073246002197 0.9374483225537542\n",
      "4.113913059234619 0.9691133068210213\n",
      "4.080438613891602 0.9136206295469307\n",
      "4.101089954376221 0.8983473512372456\n",
      "2.3190362453460693 0.9134389133605061\n",
      "3.842298746109009 0.9180742796956516\n",
      "3.8774573802948 0.9616093211548197\n",
      "4.016642093658447 0.8959850443312435\n",
      "3.8699448108673096 0.8822716111018865\n",
      "3.1284103393554688 0.8812171099192495\n",
      "3.6916542053222656 0.9262291746860833\n",
      "4.121885299682617 0.7264177050312977\n",
      "3.6603963375091553 0.9360011472830947\n",
      "4.138619899749756 0.9551534604935052\n",
      "4.037930011749268 0.9334130225661023\n",
      "3.841933250427246 0.9092286012357714\n",
      "4.148689270019531 0.9130930575421142\n",
      "4.095865726470947 0.9620420788417607\n",
      "3.9237656593322754 0.947620032664846\n",
      "3.896754503250122 0.9504790545398009\n",
      "4.156104564666748 0.9532007181559529\n",
      "3.6407556533813477 0.9678523281114049\n",
      "3.612778425216675 0.9556154157142889\n",
      "3.8322455883026123 0.9485394033313699\n",
      "3.831533670425415 0.9132490491446592\n",
      "4.057136058807373 0.8936557154705473\n",
      "4.137021541595459 0.9533420111531224\n",
      "4.15851354598999 0.9090064379136344\n",
      "3.6948225498199463 0.9055185769753051\n",
      "4.008750915527344 0.9001680544158702\n",
      "3.595674991607666 0.8866256215835254\n",
      "4.12768030166626 0.9339866356651758\n",
      "4.122303009033203 0.962985335827295\n",
      "3.838169574737549 0.9542647046729131\n",
      "3.90893816947937 0.916079112109491\n",
      "4.055614948272705 0.9428224917900716\n",
      "3.7086594104766846 0.9557038243852625\n",
      "4.036240577697754 0.9602821436507575\n",
      "3.9289915561676025 0.9254510140036109\n",
      "3.894697904586792 0.9380526798769727\n",
      "3.695657968521118 0.9367093702105185\n",
      "3.9828035831451416 0.9251838672738949\n",
      "3.741502046585083 0.9464270370770662\n",
      "3.7491040229797363 0.9304235809515505\n",
      "4.016482830047607 0.9282367033818016\n",
      "3.900714635848999 0.9551410445491828\n",
      "4.002762317657471 0.9452384721220063\n",
      "4.093390464782715 0.9415983284803677\n",
      "3.9268527030944824 0.8629697543905056\n",
      "4.102797031402588 0.9450281544493964\n",
      "3.959352731704712 0.9404305890286968\n",
      "4.173182010650635 0.9282456662361879\n",
      "3.734567642211914 0.9659363484589544\n",
      "3.9936439990997314 0.9665562262235057\n",
      "3.808828115463257 0.9535402785310693\n",
      "3.892003059387207 0.9480632497453476\n",
      "4.1541972160339355 0.8529646627327666\n",
      "3.8921031951904297 0.9492829175956483\n",
      "4.042595386505127 0.9400796003588962\n",
      "3.796321392059326 0.9243684238815016\n",
      "4.203639507293701 0.9706701850721977\n",
      "4.019858360290527 0.9649787068984671\n",
      "4.037337779998779 0.9143625407668494\n",
      "4.042809009552002 0.9481903130995674\n",
      "3.7318196296691895 0.9426082809838046\n",
      "3.7269155979156494 0.9314410547570837\n",
      "3.6334195137023926 0.899051781349769\n",
      "3.9591732025146484 0.9490733822361841\n",
      "3.8216898441314697 0.9338794924451564\n",
      "4.198265075683594 0.8540578158380093\n",
      "3.7809038162231445 0.929806888880862\n",
      "3.7487354278564453 0.9481639354032572\n",
      "3.4132096767425537 0.9331036052693092\n",
      "3.9434261322021484 0.9461389284977307\n",
      "3.6362035274505615 0.9611700818637274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.048877716064453 0.9026332580645122\n",
      "3.977673053741455 0.9276013028463833\n",
      "3.89854097366333 0.943941459714312\n",
      "3.64083194732666 0.9266418057449972\n",
      "3.9163401126861572 0.9589973780770495\n",
      "4.0998992919921875 0.9149618051420406\n",
      "3.796144962310791 0.8939574406351539\n",
      "3.913281202316284 0.9267942961035871\n",
      "4.155980110168457 0.9456798359200081\n",
      "4.205958843231201 0.8994909583104632\n",
      "3.662231922149658 0.8970200729522372\n",
      "4.097925186157227 0.9562093887761212\n",
      "3.9823291301727295 0.922785762592938\n",
      "4.076147079467773 0.8762579042524999\n",
      "3.7466771602630615 0.9630707137811028\n",
      "3.865732431411743 0.881467845045764\n",
      "3.08378529548645 0.9457249682195783\n",
      "3.862584352493286 0.9249804606556553\n",
      "3.5757369995117188 0.9490118636276406\n",
      "3.948655128479004 0.905435636227668\n",
      "3.8732590675354004 0.9208543219945516\n",
      "3.915001630783081 0.9241254543067056\n",
      "3.8503425121307373 0.9321013397088039\n",
      "3.9215872287750244 0.9606535929177095\n",
      "4.111632347106934 0.9381826417559817\n",
      "4.1247334480285645 0.9084518222116467\n",
      "3.9451913833618164 0.8975426950211943\n",
      "4.031282424926758 0.9199167281902604\n",
      "4.026589393615723 0.954082087587437\n",
      "4.051695823669434 0.939521968666251\n",
      "4.1833815574646 0.9470633465275066\n",
      "4.181420803070068 0.9027781724223323\n",
      "3.998981475830078 0.9568016914297494\n",
      "3.528728723526001 0.9355378054642476\n",
      "3.879850387573242 0.9229375383584246\n",
      "4.081507205963135 0.9285781163354918\n",
      "3.8568177223205566 0.9612172419917061\n",
      "4.047900676727295 0.9127321433223214\n",
      "3.996901035308838 0.9250819431497743\n",
      "4.007254123687744 0.9175587616015018\n",
      "3.934842586517334 0.9542566024578144\n",
      "3.84369158744812 0.8878791853905856\n",
      "3.857450246810913 0.9276551444609201\n",
      "4.16264009475708 0.956158991807806\n",
      "3.7906947135925293 0.9601033797440434\n",
      "3.5118038654327393 0.9571790103617271\n",
      "3.886820077896118 0.9483415516682787\n",
      "3.9523229598999023 0.9222996524821685\n",
      "4.001209735870361 0.9572411982827858\n",
      "3.694797992706299 0.9449589235576084\n",
      "3.8278770446777344 0.9359416726129172\n",
      "3.769171714782715 0.958848642739264\n",
      "3.8531460762023926 0.9410158868732302\n",
      "3.8307394981384277 0.9540582388438829\n",
      "3.9108245372772217 0.9161391236363376\n",
      "3.8256800174713135 0.9667930085313585\n",
      "3.975388288497925 0.8919825874787566\n",
      "3.756197214126587 0.9381255250152515\n",
      "4.099001884460449 0.9666302237108704\n",
      "3.6488049030303955 0.8921066225890546\n",
      "3.9817848205566406 0.929690926172846\n",
      "4.207592487335205 0.8665219312308118\n",
      "4.139398574829102 0.8974515295431869\n",
      "4.127771377563477 0.9438046593212737\n",
      "3.941632032394409 0.9064384470249259\n",
      "3.6823692321777344 0.8530293465255929\n",
      "3.7963154315948486 0.9348973130383191\n",
      "3.986464738845825 0.9379657465729891\n",
      "4.035507678985596 0.954432865869961\n",
      "3.7087440490722656 0.9315007181508607\n",
      "3.9674324989318848 0.939836267969695\n",
      "4.021552562713623 0.9423807195358321\n",
      "4.035770893096924 0.9338699483301641\n",
      "3.846846103668213 0.9721193330351894\n",
      "3.935856342315674 0.9230462751884936\n",
      "4.062506675720215 0.9078747666802905\n",
      "3.892183780670166 0.9112838463711712\n",
      "4.013542175292969 0.8995122229736704\n",
      "3.812406539916992 0.9525701756838909\n",
      "3.9982211589813232 0.9220299944237553\n",
      "3.9933104515075684 0.9006783906142133\n",
      "4.131217002868652 0.9356014707820607\n",
      "3.7800049781799316 0.9400958745116671\n",
      "3.711679697036743 0.9480059409755557\n",
      "3.9795737266540527 0.9299362275009998\n",
      "4.038817882537842 0.9615400417323563\n",
      "3.926969051361084 0.9539549003841894\n",
      "3.8879594802856445 0.9498210379124585\n",
      "3.9814810752868652 0.8821356938397875\n",
      "4.0115156173706055 0.9363346705513138\n",
      "3.8764801025390625 0.8997269198564424\n",
      "3.901942729949951 0.9168057086861446\n",
      "4.294229030609131 0.9643806021277784\n",
      "4.045215606689453 0.8697742355350074\n",
      "4.023123264312744 0.9098598507113778\n",
      "4.099903583526611 0.9247306653642254\n",
      "4.131407737731934 0.9707557311784707\n",
      "4.047585487365723 0.94772995407542\n",
      "3.915541410446167 0.9028323581528902\n",
      "4.002581596374512 0.9532585986013002\n",
      "4.084644794464111 0.9589451154093968\n",
      "4.00335693359375 0.9128191527521639\n",
      "3.763890504837036 0.9288752019715578\n",
      "3.8483662605285645 0.8644759864708843\n",
      "3.431356191635132 0.9326290925737142\n",
      "3.9232237339019775 0.9436765563749647\n",
      "4.075717449188232 0.9160635216227679\n",
      "3.957918643951416 0.9285437919043799\n",
      "4.2482500076293945 0.9259386345305425\n",
      "3.9134347438812256 0.876518555473803\n",
      "4.003862380981445 0.9105902001513351\n",
      "4.010505676269531 0.9400439676568286\n",
      "4.328771114349365 0.9248345499657747\n",
      "3.652531147003174 0.9381018512405621\n",
      "3.4058337211608887 0.9333842725507653\n",
      "4.058573246002197 0.9662628094013925\n",
      "4.018370628356934 0.9400716444830909\n",
      "3.6034209728240967 0.9616649906869694\n",
      "4.075123310089111 0.9145048859168052\n",
      "3.8822743892669678 0.907385978308767\n",
      "3.928157091140747 0.878825801470337\n",
      "3.7456319332122803 0.9555194230243474\n",
      "4.013180255889893 0.9219357127466371\n",
      "4.018887042999268 0.9297081256096339\n",
      "4.0223917961120605 0.9192771319224359\n",
      "4.038441181182861 0.9199252392351297\n",
      "4.040764808654785 0.9623781611221912\n",
      "3.811223030090332 0.9452975508892015\n",
      "4.1525163650512695 0.9228008225382034\n",
      "3.521674871444702 0.9292773201455125\n",
      "4.037266731262207 0.9224083365458735\n",
      "3.823787212371826 0.9571856458109992\n",
      "3.9486587047576904 0.9348375666701887\n",
      "4.028339385986328 0.9317719977229935\n",
      "4.086219310760498 0.9294921737578579\n",
      "3.928408145904541 0.9488439955172653\n",
      "4.002603530883789 0.9323442473682018\n",
      "4.027069568634033 0.9224348878115621\n",
      "3.9890003204345703 0.9367755540231997\n",
      "4.075826644897461 0.8967654195181469\n",
      "4.205106735229492 0.9237011549527806\n",
      "3.6449153423309326 0.8527264594246207\n",
      "4.057188510894775 0.9530164955973648\n",
      "4.003110408782959 0.9390978909475555\n",
      "3.9733171463012695 0.92172536462974\n",
      "3.7147204875946045 0.9050031950512096\n",
      "3.9138846397399902 0.948109354518675\n",
      "4.011291027069092 0.9318354497437025\n",
      "3.8025972843170166 0.9360817848535454\n",
      "4.011180400848389 0.9340865292231207\n",
      "3.8906877040863037 0.9283516353196856\n",
      "4.128052234649658 0.9429829963933798\n",
      "4.1005635261535645 0.9141383796644043\n",
      "3.9765446186065674 0.9553540627910517\n",
      "3.917213201522827 0.9468511586352859\n",
      "3.764493703842163 0.9501539048758717\n",
      "3.8566653728485107 0.82877241821832\n",
      "3.8916170597076416 0.9109506204749979\n",
      "4.079160690307617 0.9490688436069378\n",
      "3.5032222270965576 0.9394518118322641\n",
      "3.6872353553771973 0.8953471292541131\n",
      "3.465287685394287 0.9430746162474959\n",
      "3.9633333683013916 0.9624932310229195\n",
      "4.202407360076904 0.9548995660491737\n",
      "3.7379860877990723 0.9676437689217018\n",
      "3.924255132675171 0.9562715692453333\n",
      "3.7245194911956787 0.9567272869506167\n",
      "4.10405969619751 0.9444961022302698\n",
      "3.8415889739990234 0.8977971196795644\n",
      "4.174529075622559 0.9557153017550979\n",
      "3.9826266765594482 0.9176854020688284\n",
      "3.9197819232940674 0.9608631668509177\n",
      "3.640298843383789 0.8948631316415392\n",
      "4.010930061340332 0.9424321820934622\n",
      "3.946242570877075 0.9551867980486505\n",
      "3.841172456741333 0.939297268407727\n",
      "3.9798355102539062 0.9141251633970909\n",
      "3.9204909801483154 0.9139739871169986\n",
      "3.76789927482605 0.9295496199315817\n",
      "3.933121919631958 0.9424101703843588\n",
      "4.011352062225342 0.9500442254758092\n",
      "4.008569240570068 0.8902739037376994\n",
      "4.075542449951172 0.9389030278636865\n",
      "3.952596426010132 0.9449775214139795\n",
      "3.822270154953003 0.9482144822578618\n",
      "3.996492862701416 0.9399577636317133\n",
      "3.983276844024658 0.9265183805544078\n",
      "3.910759687423706 0.946083555469359\n",
      "3.940089464187622 0.9358226600111255\n",
      "3.937394142150879 0.8763173975505097\n",
      "3.7813339233398438 0.9203854846546153\n",
      "3.773881673812866 0.9553210463465406\n",
      "3.7660295963287354 0.943026846386633\n",
      "4.030768394470215 0.9473863794522012\n",
      "4.102835178375244 0.9293302952239156\n",
      "3.899371862411499 0.9215112219846583\n",
      "3.8830816745758057 0.8630400920945936\n",
      "4.009266376495361 0.9671392975581198\n",
      "4.14855432510376 0.967475720298048\n",
      "3.6442461013793945 0.8856268247362953\n",
      "3.7583794593811035 0.9121581536702935\n",
      "4.068759441375732 0.9536563797543027\n",
      "3.694611072540283 0.959429686961259\n",
      "3.5543367862701416 0.9225428970997925\n",
      "3.4545578956604004 0.8719082029884008\n",
      "3.4744391441345215 0.8113285689149682\n",
      "3.93135404586792 0.8425099368904846\n",
      "3.6030821800231934 0.9273308651150475\n",
      "3.673250436782837 0.9051789129193573\n",
      "3.5185294151306152 0.9032113472703983\n",
      "3.703763008117676 0.9405483397517741\n",
      "3.7499639987945557 0.9319735599858107\n",
      "3.890599250793457 0.8737535306440745\n",
      "3.7770450115203857 0.9264186620792151\n",
      "3.599337577819824 0.896148680179372\n",
      "3.7876505851745605 0.8917727941429406\n",
      "3.680187463760376 0.9375568163799709\n",
      "3.6312124729156494 0.8968378109536215\n",
      "3.4881465435028076 0.9328244838084794\n",
      "3.7762131690979004 0.9159666243068215\n",
      "3.5522818565368652 0.8757060573935824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4980106353759766 0.926431121801606\n",
      "3.5294337272644043 0.9265482932452979\n",
      "3.6626908779144287 0.8860372776388502\n",
      "3.9592480659484863 0.8963856688378341\n",
      "3.6328999996185303 0.8904570054534261\n",
      "3.666865825653076 0.9223741211618695\n",
      "3.79062557220459 0.9138121793924909\n",
      "3.8238184452056885 0.9281652623509872\n",
      "3.4452970027923584 0.950877069154091\n",
      "3.5122342109680176 0.8349972898880738\n",
      "3.5616259574890137 0.924176225462808\n",
      "3.5580413341522217 0.8772366073448985\n",
      "3.2949469089508057 0.9519943999563517\n",
      "3.8193469047546387 0.9241637219026365\n",
      "3.7409017086029053 0.8866463956406742\n",
      "3.8120665550231934 0.86958511525301\n",
      "3.586498737335205 0.9143169693749437\n",
      "3.5754172801971436 0.8875507234411087\n",
      "3.5506324768066406 0.8804249970595223\n",
      "3.986039161682129 0.8926800352087394\n",
      "3.9236133098602295 0.8834188943733551\n",
      "3.833554744720459 0.9196001786058515\n",
      "3.7594268321990967 0.9293592218773692\n",
      "3.4485280513763428 0.8562902237665074\n",
      "3.758467435836792 0.9163842367146344\n",
      "3.5875775814056396 0.8698665113928112\n",
      "3.808424949645996 0.8738225081173893\n",
      "3.7598612308502197 0.9262586771571389\n",
      "3.8099353313446045 0.8727126386966526\n",
      "3.520798683166504 0.9059503634320466\n",
      "3.380732774734497 0.9234442037210653\n",
      "3.816831111907959 0.8739603315943283\n",
      "3.5904271602630615 0.8809562016516569\n",
      "3.830791711807251 0.936068483229238\n",
      "3.674901008605957 0.9261339078203092\n",
      "3.4602625370025635 0.8655968187611244\n",
      "3.2062880992889404 0.9115487294638489\n",
      "3.540404796600342 0.8901951031952445\n",
      "3.8564343452453613 0.9163452857437532\n",
      "3.550163507461548 0.8142750553576236\n",
      "3.681520462036133 0.8945015162611349\n",
      "3.7915165424346924 0.8677500653864015\n",
      "3.618393659591675 0.9274956341118137\n",
      "3.8843729496002197 0.8571949509411574\n",
      "3.293186664581299 0.8909910941296072\n",
      "3.488186836242676 0.9179287113777503\n",
      "3.5705325603485107 0.9180603746996545\n",
      "3.2717907428741455 0.9097292153306868\n",
      "3.350522518157959 0.9082633942493392\n",
      "3.871135711669922 0.9260359868969922\n",
      "3.28407621383667 0.8658780694201674\n",
      "3.513373374938965 0.9116725079053501\n",
      "3.56453537940979 0.8888614817395665\n",
      "3.266610622406006 0.9050662857286593\n",
      "3.880084276199341 0.91562013421142\n",
      "3.799960136413574 0.916995148193941\n",
      "3.4717330932617188 0.9235505763350312\n",
      "3.6030266284942627 0.892197460607088\n",
      "3.8415560722351074 0.908315698462906\n",
      "3.806518793106079 0.8945441193623911\n",
      "3.847829818725586 0.9107826170318162\n",
      "3.958913564682007 0.8886734591176741\n",
      "3.7417964935302734 0.8997203865659054\n",
      "3.7871479988098145 0.9368605379584942\n",
      "3.7860891819000244 0.85721155309989\n",
      "2.951639175415039 0.9197756950852837\n",
      "3.3798394203186035 0.8914005823286248\n",
      "3.529229164123535 0.9055544156558065\n",
      "3.6109671592712402 0.8708480744096609\n",
      "3.9796831607818604 0.891150503164207\n",
      "3.8602049350738525 0.9344216090200198\n",
      "4.014068126678467 0.9438381691569079\n",
      "3.6108341217041016 0.9033804167109726\n",
      "3.8127715587615967 0.872609194474869\n",
      "3.858219623565674 0.8834202078880979\n",
      "3.6522624492645264 0.8936460927433383\n",
      "3.727719783782959 0.8670527892407298\n",
      "3.7452549934387207 0.9207513829200538\n",
      "3.2609312534332275 0.952353126747797\n",
      "3.9771106243133545 0.8706479973495552\n",
      "4.063020706176758 0.9079332460695223\n",
      "3.9957759380340576 0.9089084405401184\n",
      "3.476705312728882 0.9201003631935551\n",
      "3.7350289821624756 0.8727588002539851\n",
      "3.376232624053955 0.8710764002819519\n",
      "3.4967522621154785 0.9085199586073189\n",
      "3.5245344638824463 0.9258187487684838\n",
      "3.4673306941986084 0.9059440683775734\n",
      "3.4601998329162598 0.8952016461058017\n",
      "3.7665963172912598 0.9143106304820829\n",
      "3.8714356422424316 0.8788757632959754\n",
      "3.7817695140838623 0.9100505090059241\n",
      "3.92337965965271 0.9164650093364514\n",
      "3.1813137531280518 0.9029138551437093\n",
      "3.739898443222046 0.9039531704171636\n",
      "3.708568572998047 0.9251393183454191\n",
      "3.667733669281006 0.907317213275125\n",
      "3.2568325996398926 0.90650952814897\n",
      "3.6886465549468994 0.9198576192741597\n",
      "3.493617534637451 0.8831571382682699\n",
      "3.583893060684204 0.9399070568585614\n",
      "3.938727617263794 0.8936301781572155\n",
      "3.2637741565704346 0.9049764548467215\n",
      "3.751429319381714 0.8942879290001534\n",
      "3.705413818359375 0.8563585025413354\n",
      "3.2330973148345947 0.8597336656201355\n",
      "3.979363203048706 0.8764093475859709\n",
      "3.4912643432617188 0.8163331222139925\n",
      "3.753295421600342 0.932743247213822\n",
      "3.232760429382324 0.9418199512458798\n",
      "3.6231741905212402 0.9315605396978468\n",
      "3.3939404487609863 0.9374348126620999\n",
      "3.4434375762939453 0.8882320689575116\n",
      "3.764237880706787 0.8505029543094673\n",
      "4.0096893310546875 0.9325898137777567\n",
      "3.650620222091675 0.9186975435546724\n",
      "3.650681972503662 0.908033269016337\n",
      "3.944502353668213 0.8953769191967264\n",
      "3.545232057571411 0.9100043522163819\n",
      "3.146522045135498 0.8905223408800444\n",
      "3.7277610301971436 0.8769120376790316\n",
      "3.424196720123291 0.9479063891270105\n",
      "3.5854804515838623 0.892803780530515\n",
      "3.292593479156494 0.894596634516597\n",
      "3.2225897312164307 0.9276455532848781\n",
      "3.8319268226623535 0.8090840377462151\n",
      "3.840120792388916 0.8932585243998822\n",
      "3.303331136703491 0.9390832986568669\n",
      "3.292264223098755 0.9125832862611508\n",
      "3.4409091472625732 0.8941119554881239\n",
      "3.659524917602539 0.9210705090554059\n",
      "3.838047742843628 0.8941223577167449\n",
      "3.265056610107422 0.8644095654253798\n",
      "3.0604662895202637 0.9614119078327221\n",
      "3.710890769958496 0.813722499199112\n",
      "3.705650806427002 0.8999174543371932\n",
      "3.828835964202881 0.9226311308130362\n",
      "3.8385729789733887 0.8938266167931086\n",
      "3.4966421127319336 0.9329447844406896\n",
      "3.5123186111450195 0.9217062456040445\n",
      "3.6211819648742676 0.8924431145172211\n",
      "3.638420820236206 0.9307837538683885\n",
      "3.157588243484497 0.9168545490966689\n",
      "3.8811705112457275 0.9031129067971019\n",
      "3.3070316314697266 0.9181400140757383\n",
      "3.5428059101104736 0.9382952681923281\n",
      "3.75350284576416 0.9278187571481193\n",
      "3.9302964210510254 0.8591180929258041\n",
      "3.5212724208831787 0.9072290031633681\n",
      "3.114447832107544 0.9017580601267855\n",
      "3.3818325996398926 0.8931673467327361\n",
      "4.152334690093994 0.8401341807507715\n",
      "3.6293277740478516 0.9471647032963022\n",
      "3.8465559482574463 0.9127873987488526\n",
      "3.7509121894836426 0.9031874982995016\n",
      "3.764223337173462 0.8952177498851613\n",
      "2.6191461086273193 0.9385820837310159\n",
      "3.420017957687378 0.8889170783090509\n",
      "3.399541139602661 0.9094819438410993\n",
      "3.537137508392334 0.8666506762095979\n",
      "3.547340154647827 0.8848477131492399\n",
      "3.3080921173095703 0.9202818935866838\n",
      "3.5910048484802246 0.9065813004645019\n",
      "3.8947818279266357 0.9015782653501517\n",
      "3.5752570629119873 0.8557151094537889\n",
      "4.010075092315674 0.8763879416777274\n",
      "3.699475049972534 0.8976717705914524\n",
      "3.611210823059082 0.9011777920414559\n",
      "3.3674283027648926 0.872985940394559\n",
      "3.905717611312866 0.8733219438973536\n",
      "3.9726696014404297 0.8934151067935175\n",
      "3.8440961837768555 0.8971642590735992\n",
      "3.5560669898986816 0.921254743670482\n",
      "3.3938231468200684 0.8788551643153772\n",
      "3.7485718727111816 0.9479654567020389\n",
      "3.422337055206299 0.931806081787384\n",
      "3.7163162231445312 0.9419443119730565\n",
      "3.698540449142456 0.8983575747165211\n",
      "3.7745113372802734 0.9016067637238961\n",
      "3.840362787246704 0.8950374566421766\n",
      "3.4662508964538574 0.8961502542287211\n",
      "3.4982402324676514 0.9528589797085417\n",
      "3.3225769996643066 0.94070304287222\n",
      "3.6355178356170654 0.9239275682385789\n",
      "3.625797986984253 0.9433810456553836\n",
      "3.805124521255493 0.9264377808539749\n",
      "3.64748477935791 0.9055966683796137\n",
      "3.6619932651519775 0.9243346414288347\n",
      "2.9072821140289307 0.8711436612694082\n",
      "3.6809310913085938 0.8679293201561374\n",
      "3.1475069522857666 0.8826254498016394\n",
      "2.9475669860839844 0.908973844509013\n",
      "4.110691070556641 0.8637670181048887\n",
      "3.6422760486602783 0.8879212001580409\n",
      "3.8303346633911133 0.8812581132766366\n",
      "3.7616817951202393 0.9167556623598327\n",
      "3.8770501613616943 0.9140562176183304\n",
      "3.666672706604004 0.8694927419981897\n",
      "3.1998558044433594 0.8955252463549126\n",
      "3.796992540359497 0.895546214641489\n",
      "3.938499927520752 0.948457462625493\n",
      "4.062528610229492 0.9029605964400829\n",
      "3.5152587890625 0.9280929928336188\n",
      "3.5692763328552246 0.9122156449956458\n",
      "3.6708176136016846 0.868393124296046\n",
      "3.5687737464904785 0.903672568478719\n",
      "3.070651054382324 0.8996844463815808\n",
      "3.693880319595337 0.9238659365243698\n",
      "3.8211467266082764 0.8810892477472324\n",
      "3.3990116119384766 0.8994110565676989\n",
      "3.9010097980499268 0.8929386869129491\n",
      "3.8529207706451416 0.8794904177298198\n",
      "3.589320182800293 0.9043728407820013\n",
      "3.6065053939819336 0.9155319601677514\n",
      "3.3773581981658936 0.908750503110994\n",
      "3.731393814086914 0.8865445781831461\n",
      "4.041451930999756 0.8792376336491611\n",
      "3.2684664726257324 0.9122518125306154\n",
      "3.29192852973938 0.9361838477429042\n",
      "3.9829633235931396 0.9175686094317528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.719381332397461 0.9035113889404941\n",
      "3.5471720695495605 0.9243016453414565\n",
      "3.413867712020874 0.9277665379275314\n",
      "3.4278547763824463 0.9492799725620704\n",
      "3.5989933013916016 0.8899624700501195\n",
      "3.894541025161743 0.92515307486635\n",
      "3.42376971244812 0.8841010429112548\n",
      "3.713862180709839 0.8842303734578497\n",
      "3.464634418487549 0.8974804048888954\n",
      "3.248751640319824 0.949145527937616\n",
      "3.7641096115112305 0.8829616913132649\n",
      "3.539133071899414 0.9053082046598183\n",
      "3.5295944213867188 0.9217741202405221\n",
      "3.7632741928100586 0.9175163070692252\n",
      "3.1189656257629395 0.9038768358615181\n",
      "3.826298475265503 0.907509006086698\n",
      "3.8253121376037598 0.8963462762693196\n",
      "3.665754556655884 0.9546437427103392\n",
      "3.548102617263794 0.8193117284167134\n",
      "3.9988648891448975 0.9208895007012086\n",
      "3.7558929920196533 0.94502683935484\n",
      "3.5935375690460205 0.8948926697404207\n",
      "3.7174103260040283 0.9187411925709966\n",
      "3.9561033248901367 0.9159401903303087\n",
      "3.9265666007995605 0.8178288353958788\n",
      "3.9757955074310303 0.9208870590737754\n",
      "3.6464157104492188 0.8874357790063445\n",
      "3.4709229469299316 0.9263684910432624\n",
      "3.5750410556793213 0.9251840260800368\n",
      "3.76362681388855 0.8457092317362757\n",
      "3.5330638885498047 0.9291791176813934\n",
      "4.041651725769043 0.786060422095508\n",
      "3.7481751441955566 0.9276539382112834\n",
      "3.909158945083618 0.9105116523114897\n",
      "3.6467747688293457 0.9077041950577069\n",
      "3.5353453159332275 0.8951251957373698\n",
      "3.405956268310547 0.8812648020428202\n",
      "3.788766622543335 0.9129751560541065\n",
      "3.805027723312378 0.8869197390136225\n",
      "3.387510299682617 0.8975117823862768\n",
      "3.686943531036377 0.8848687675428448\n",
      "3.5721216201782227 0.9162585997468492\n",
      "3.689925193786621 0.9180203846014597\n",
      "3.4912281036376953 0.8926164948989144\n",
      "3.9676318168640137 0.8913815615369215\n",
      "3.5605647563934326 0.8826605896530727\n",
      "3.392078399658203 0.9196623647573284\n",
      "3.624051570892334 0.9264265543804859\n",
      "2.8592495918273926 0.9080640709193527\n",
      "2.9995505809783936 0.8944092155136001\n",
      "3.9649479389190674 0.8283371922815251\n",
      "4.13777494430542 0.87747038853938\n",
      "2.8752079010009766 0.908253403460687\n",
      "3.02333402633667 0.8683718040807821\n",
      "3.314621686935425 0.9016205725014458\n",
      "3.7406108379364014 0.9417914891270339\n",
      "3.885056734085083 0.8745281481005467\n",
      "3.084482192993164 0.8864204295547463\n",
      "3.857717752456665 0.8779635750091493\n",
      "3.5018742084503174 0.915918803654139\n",
      "3.476868152618408 0.9124641938331671\n",
      "3.7485251426696777 0.8827683087360744\n",
      "3.7539007663726807 0.850921851704557\n",
      "3.6253294944763184 0.8570106949965703\n",
      "3.981743812561035 0.9064968358935979\n",
      "4.046292781829834 0.888366638098395\n",
      "3.740635871887207 0.9467584714808298\n",
      "3.3314969539642334 0.9257867970061033\n",
      "3.6778335571289062 0.926463736674204\n",
      "3.89046311378479 0.8759186771122709\n",
      "3.6427252292633057 0.9380272472780034\n",
      "3.8349616527557373 0.8747182685352232\n",
      "3.7254912853240967 0.8763469515725014\n",
      "3.5715136528015137 0.92546584772229\n",
      "2.704545497894287 0.8814437701167652\n",
      "3.5270004272460938 0.9509786504600867\n",
      "3.5545005798339844 0.9125063323403861\n",
      "3.3967676162719727 0.9406309449870369\n",
      "3.4455063343048096 0.9214118328228541\n",
      "3.762535810470581 0.8808045136638608\n",
      "3.98341703414917 0.9248236518013442\n",
      "3.6522159576416016 0.923043808159752\n",
      "3.9165663719177246 0.8873125750743679\n",
      "3.473524332046509 0.9210262699152342\n",
      "3.63796329498291 0.8882141473519787\n",
      "3.5823097229003906 0.8576624649263506\n",
      "3.517176389694214 0.900874987794124\n",
      "3.815100908279419 0.9312501957542211\n",
      "3.2497434616088867 0.8387460494847049\n",
      "3.839305877685547 0.8998223326837057\n",
      "3.5605838298797607 0.8763150897945725\n",
      "3.1101298332214355 0.8975210889747227\n",
      "3.7278308868408203 0.9158400517824321\n",
      "3.519350528717041 0.9438938499766963\n",
      "4.0264105796813965 0.8549335192491033\n",
      "3.635409116744995 0.8188428054102755\n",
      "3.5819759368896484 0.9126759737451117\n",
      "3.2710025310516357 0.9342856342027238\n",
      "3.750577688217163 0.8787923817119039\n",
      "3.600802421569824 0.9398843836612947\n",
      "3.55715012550354 0.9027553659108196\n",
      "3.361025810241699 0.9118615924531625\n",
      "3.8279175758361816 0.9562091385303668\n",
      "3.174556255340576 0.8966771863169792\n",
      "3.7917234897613525 0.9254366438743651\n",
      "3.922884464263916 0.8781024790821857\n",
      "3.196448802947998 0.8476843253309536\n",
      "3.7313942909240723 0.9223980908680062\n",
      "3.7688028812408447 0.8086705736227479\n",
      "3.560593605041504 0.9357113192420531\n",
      "3.567122459411621 0.8644692421437323\n",
      "3.7241058349609375 0.9066919384433737\n",
      "3.9300763607025146 0.9111698773306517\n",
      "4.193854331970215 0.8975901127544355\n",
      "3.486999273300171 0.900122509942441\n",
      "3.622199058532715 0.8613171963674896\n",
      "3.7454962730407715 0.8749794664650794\n",
      "3.7903449535369873 0.8958168088197567\n",
      "3.9462854862213135 0.9051578775722423\n",
      "3.551720142364502 0.8864213439109083\n",
      "2.7156317234039307 0.9270094245228367\n",
      "3.4175174236297607 0.9311667896943274\n",
      "3.6079440116882324 0.9396405649911669\n",
      "3.314734935760498 0.8961521707356701\n",
      "3.619657278060913 0.9441947158301692\n",
      "4.104284763336182 0.8971372210673151\n",
      "3.492906093597412 0.9091424016033758\n",
      "3.5823123455047607 0.924599710744297\n",
      "3.756105422973633 0.9335583922393705\n",
      "3.6804652214050293 0.9255036242478919\n",
      "3.657923698425293 0.8715245154671003\n",
      "3.5812735557556152 0.9332866821027869\n",
      "3.715311288833618 0.8636245231657891\n",
      "3.680272340774536 0.9202145228695294\n",
      "3.6034486293792725 0.9399272085238682\n",
      "3.7284741401672363 0.9046446297613546\n",
      "3.721266984939575 0.9123178894176855\n",
      "3.6998817920684814 0.8897869538619606\n",
      "3.815600633621216 0.9039477867471128\n",
      "3.8951706886291504 0.8918124328529324\n",
      "3.6925761699676514 0.8860108542255677\n",
      "3.255481243133545 0.93114942201013\n",
      "3.734513521194458 0.9084213424960469\n",
      "3.653970956802368 0.9263798128518546\n",
      "3.007328748703003 0.8718885280146179\n",
      "3.4559457302093506 0.8914544880553715\n",
      "3.0915184020996094 0.8826355160315977\n",
      "3.2797064781188965 0.901774118680172\n",
      "3.5573012828826904 0.8745314715008864\n",
      "4.04347038269043 0.8970421295911919\n",
      "3.8193681240081787 0.8851791122222926\n",
      "3.6051058769226074 0.85119922965542\n",
      "3.193098783493042 0.8604767095843855\n",
      "3.268467903137207 0.9170762396558395\n",
      "3.7532999515533447 0.9088655032613709\n",
      "3.807715654373169 0.8282827187328355\n",
      "3.8411920070648193 0.9408054409261465\n",
      "3.394716262817383 0.8756472633862665\n",
      "4.074550151824951 0.8379656049223226\n",
      "3.4398653507232666 0.9066072734244195\n",
      "3.9260475635528564 0.9466848271219493\n",
      "3.8247129917144775 0.8952046959006075\n",
      "3.9119150638580322 0.8278198442541654\n",
      "3.705496311187744 0.9226303859424663\n",
      "3.7202887535095215 0.905621049419951\n",
      "2.7716212272644043 0.9151041634076204\n",
      "3.778886079788208 0.8801350633765364\n",
      "3.202890634536743 0.9344121378317296\n",
      "3.7448935508728027 0.8889608946239195\n",
      "3.8264598846435547 0.9088150188485761\n",
      "3.6081838607788086 0.8768857433334531\n",
      "3.787198781967163 0.907839169750983\n",
      "2.690922498703003 0.8853856571004618\n",
      "3.6005492210388184 0.8722707846622559\n",
      "3.21802020072937 0.9142196226643269\n",
      "3.7837014198303223 0.9177323578043803\n",
      "3.698436737060547 0.8511464675169385\n",
      "3.3353776931762695 0.9313665960625886\n",
      "3.8129100799560547 0.9140631141064106\n",
      "3.573456287384033 0.9255004998915705\n",
      "3.3436083793640137 0.8617954053169935\n",
      "3.4627208709716797 0.8949033176167208\n",
      "3.215233564376831 0.9060329551642416\n",
      "3.6883130073547363 0.9035328042411068\n",
      "3.229421377182007 0.9329568804375494\n",
      "3.8996262550354004 0.9384989127157991\n",
      "3.7226102352142334 0.9305321472443697\n",
      "3.930917739868164 0.9446393250922419\n",
      "4.0032453536987305 0.9056360736870538\n",
      "3.9674904346466064 0.9067868223306189\n",
      "4.014800548553467 0.9107195822801114\n",
      "4.052734375 0.9614349225045951\n",
      "3.376807928085327 0.8802490533762096\n",
      "3.9623095989227295 0.9399597616878211\n",
      "3.731459856033325 0.9364722797414671\n",
      "3.967439889907837 0.9380886623187048\n",
      "3.7242929935455322 0.9279541920586105\n",
      "3.6297755241394043 0.9133554807359714\n",
      "3.6468374729156494 0.9392858086433571\n",
      "4.026500225067139 0.9414521139205906\n",
      "3.333981990814209 0.9462050623632803\n",
      "3.4394211769104004 0.9328747695997811\n",
      "3.623063325881958 0.9555737437024667\n",
      "3.7298688888549805 0.9734932827372802\n",
      "3.8416588306427 0.9355583288821432\n",
      "3.9251151084899902 0.9422064430527565\n",
      "3.733424425125122 0.9427068834368346\n",
      "3.1754167079925537 0.9494744835664488\n",
      "3.4268712997436523 0.8790108620047004\n",
      "3.1624090671539307 0.9767476078293803\n",
      "3.593515396118164 0.9491894317747246\n",
      "3.5127298831939697 0.9239070813895874\n",
      "3.6132595539093018 0.9527615231252657\n",
      "3.869051933288574 0.9577668433299432\n",
      "3.2851693630218506 0.9217894693295644\n",
      "4.126561641693115 0.9171159193901814\n",
      "2.630246162414551 0.9713376233586538\n",
      "3.889342784881592 0.9535491767499529\n",
      "3.722273349761963 0.9496804433883906\n",
      "4.035114765167236 0.9564018704562142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.820943593978882 0.927446307338225\n",
      "3.695488929748535 0.9515226575031424\n",
      "3.54632830619812 0.9612074695517352\n",
      "3.495654344558716 0.9104765068921947\n",
      "3.786128520965576 0.969865988008309\n",
      "3.863041877746582 0.9027422136590453\n",
      "3.9701526165008545 0.9649759783607252\n",
      "4.044124603271484 0.9627740613417111\n",
      "3.82560396194458 0.9163750821700298\n",
      "3.955085039138794 0.9618873955140227\n",
      "3.5240113735198975 0.9593886842498156\n",
      "3.4604456424713135 0.9312163859336638\n",
      "3.354184865951538 0.9507509241506023\n",
      "3.670557737350464 0.9630779758351875\n",
      "3.6642415523529053 0.9691011052952359\n",
      "4.062143325805664 0.9206689811922582\n",
      "3.7656803131103516 0.9638278074462401\n",
      "3.80011248588562 0.9129647837031108\n",
      "3.4816396236419678 0.9050123457835949\n",
      "3.5197219848632812 0.9467520675815719\n",
      "3.639103651046753 0.9503343396037928\n",
      "3.532745599746704 0.8992907974259431\n",
      "3.7835960388183594 0.9549230620595127\n",
      "3.483949899673462 0.9336040566695752\n",
      "4.000739574432373 0.8594816805867141\n",
      "3.3649396896362305 0.9683197812541944\n",
      "3.0501902103424072 0.9313444562614072\n",
      "3.8612401485443115 0.9480247955755146\n",
      "3.7287514209747314 0.9206561096180615\n",
      "3.8014488220214844 0.865927812964648\n",
      "3.93013858795166 0.9743566500341497\n",
      "3.791971445083618 0.9189519588963253\n",
      "3.7752013206481934 0.9580930814834894\n",
      "3.6485869884490967 0.959082676312284\n",
      "2.1920502185821533 0.9275986045532084\n",
      "3.9241116046905518 0.9464171972396648\n",
      "3.9768106937408447 0.9517416037597729\n",
      "3.669766664505005 0.9731679768762065\n",
      "3.63753080368042 0.9499194085557835\n",
      "3.5157809257507324 0.9584616987322397\n",
      "3.5621652603149414 0.937222839930104\n",
      "3.594269275665283 0.8993447474008082\n",
      "3.9403209686279297 0.9572171206316072\n",
      "3.594977378845215 0.94849408441251\n",
      "3.769727945327759 0.9187509862270984\n",
      "3.6486384868621826 0.929775106441237\n",
      "3.5645079612731934 0.9451174783555332\n",
      "3.579036235809326 0.9534524670955408\n",
      "4.111236572265625 0.9373661143230348\n",
      "4.010269641876221 0.9392441382709644\n",
      "3.792144298553467 0.9536564925635811\n",
      "4.045238494873047 0.9720722040819575\n",
      "3.8112597465515137 0.9137202179041635\n",
      "3.5648136138916016 0.9584233134626619\n",
      "3.747014284133911 0.9498847255025029\n",
      "2.398853302001953 0.9566900607936946\n",
      "3.605431079864502 0.935795899902943\n",
      "3.744272470474243 0.9385245582876207\n",
      "2.1468231678009033 0.9557268225120735\n",
      "3.3789401054382324 0.9688550293775643\n",
      "3.20586895942688 0.8473802187680671\n",
      "3.928380012512207 0.8669380317139264\n",
      "3.258345365524292 0.9257162293523842\n",
      "4.228492259979248 0.9110504513610951\n",
      "3.911689519882202 0.9694834021534658\n",
      "3.6297616958618164 0.8996670200468251\n",
      "3.8674476146698 0.9582625203010072\n",
      "3.6251606941223145 0.9498746053736445\n",
      "3.5288336277008057 0.9461238966768226\n",
      "3.6491310596466064 0.9527752923143691\n",
      "3.774423122406006 0.9616397093323599\n",
      "3.794055938720703 0.9486724735189564\n",
      "3.9281091690063477 0.91929371668315\n",
      "3.687620162963867 0.9087710839458336\n",
      "3.880260944366455 0.9333288963752089\n",
      "3.4724788665771484 0.9238167092529161\n",
      "3.559448480606079 0.964912888725741\n",
      "3.419461250305176 0.9469378307135291\n",
      "3.458294630050659 0.9644656987413872\n",
      "3.4308502674102783 0.9543793862288756\n",
      "3.4156646728515625 0.9335605014088143\n",
      "4.036346435546875 0.9080035220414735\n",
      "3.519745349884033 0.8914480926931357\n",
      "4.133784294128418 0.9402377111019841\n",
      "3.930675745010376 0.856150408826054\n",
      "3.4711532592773438 0.9484962237290989\n",
      "3.5052413940429688 0.9422266036960295\n",
      "3.580059051513672 0.9372625538219225\n",
      "3.8882784843444824 0.9311681958979268\n",
      "2.4476497173309326 0.9122874669882494\n",
      "4.1501030921936035 0.9404378543732859\n",
      "3.86452054977417 0.9698453742115577\n",
      "3.8890812397003174 0.9583337684795402\n",
      "4.052780628204346 0.9325703893745373\n",
      "3.451871633529663 0.9070282307928188\n",
      "3.5795187950134277 0.963277143591565\n",
      "3.3573708534240723 0.9459453271683405\n",
      "3.7839372158050537 0.9337499425237851\n",
      "3.648808002471924 0.9560369203198827\n",
      "3.9516983032226562 0.9402259891903626\n",
      "3.4858837127685547 0.9494502324735524\n",
      "3.5074636936187744 0.9599428563119642\n",
      "3.648245096206665 0.9412911849392561\n",
      "4.07867431640625 0.9756580247236412\n",
      "3.4330146312713623 0.9526152155886217\n",
      "3.701198101043701 0.949909353254448\n",
      "4.121888160705566 0.9346986445871801\n",
      "3.446890115737915 0.9345013779870684\n",
      "4.086935043334961 0.9346398978492836\n",
      "3.6754636764526367 0.9383540505565328\n",
      "4.028886318206787 0.7860035238720471\n",
      "2.9590539932250977 0.9587395288277439\n",
      "3.8253180980682373 0.933832382928947\n",
      "3.8418569564819336 0.9576486243339887\n",
      "3.809654474258423 0.9238916867025482\n",
      "3.3766884803771973 0.9309737502947929\n",
      "3.6582062244415283 0.9453224829496175\n",
      "3.901538372039795 0.9658025682297701\n",
      "averages\n",
      "3.750408951044083 0.9184197936679426\n"
     ]
    }
   ],
   "source": [
    "paths=[]\n",
    "ind=0\n",
    "\n",
    "fs=16000\n",
    "path='/home/user/Desktop/BTP_Pratik_Lovish/timit-20230118T185105Z-001/timit'\n",
    "\n",
    "tot=0 \n",
    "pesqavg=0\n",
    "stoiavg=0\n",
    "\n",
    "\n",
    "target_folder='/home/user/Desktop/BTP_Pratik_Lovish/VCTK-Corpus/wav48'\n",
    "totest=os.listdir(target_folder)\n",
    "\n",
    "for folders in totest:\n",
    "  allfiles=os.listdir(target_folder+'/'+folders)\n",
    "  for files in allfiles:\n",
    "    if files.endswith('.wav'):\n",
    "        if tot>=1000:\n",
    "            break\n",
    "        atekhz=target_folder+'/'+folders+'/'+files\n",
    "        x, f=librosa.load(atekhz)\n",
    "        x=librosa.resample(x, f, 16000) # for vctk dataset\n",
    "        f=16000\n",
    "        Xm=[]\n",
    "        Xs=[]\n",
    "        lowed_signal=butter_lowpass_filter(x, cutoff, fs, order)\n",
    "        mf=librosa.feature.mfcc(y=lowed_signal, sr=fs//2, n_fft=frame_size, hop_length=hop_length, n_mfcc=mfccs)\n",
    "\n",
    "        # delta_mfccs = librosa.feature.delta(mf)\n",
    "        # delta2_mfccs = librosa.feature.delta(mf, order=2)\n",
    "        #xx = np.hstack((mf, delta_mfccs, delta2_mfccs))\n",
    "        #print(mf.shape, delta_mfccs.shape, delta2_mfccs.shape, xx.shape)\n",
    "        xstft = np.abs(librosa.stft(lowed_signal,n_fft=frame_size, hop_length=hop_length))\n",
    "        #print(xstft.shape)\n",
    "        xframewise=[]\n",
    "\n",
    "        for j in range(len(mf[0])):\n",
    "          z=[]\n",
    "          for i in range(len(mf)):\n",
    "            z.append(mf[i][j])\n",
    "          # for i in range(len(mf)):\n",
    "          #   z.append(delta_mfccs[i][j])\n",
    "          # for i in range(len(mf)):\n",
    "          #   z.append(delta2_mfccs[i][j])\n",
    "          Xm.append(z)\n",
    "\n",
    "        for j in range(len(xstft[0])):\n",
    "          z=[]\n",
    "          for i in range(len(xstft)):\n",
    "            z.append(xstft[i][j])\n",
    "          Xs.append(z)\n",
    "\n",
    "        #XXs.append(z)\n",
    "        # audio_framesx.append(xframewise)\n",
    "        # for i in xframewise:\n",
    "        #   XXs.append(i)\n",
    "\n",
    "        y_pred=model.predict([np.array(Xm), np.array(Xs)])\n",
    "        yFormat=[]\n",
    "\n",
    "        for j in range(len(y_pred[0])):\n",
    "            z=[]\n",
    "            for i in range(len(y_pred)):\n",
    "              z.append(y_pred[i][j])\n",
    "            yFormat.append(z)\n",
    "        toplay=[]\n",
    "        final_aud = librosa.griffinlim(np.array(yFormat), hop_length=hop_length)\n",
    "        for i in final_aud:\n",
    "            toplay.append(i)\n",
    "\n",
    "        toplay=np.array(toplay)\n",
    "        minlen=min(len(x), len(toplay))\n",
    "        score=pesq(fs,x[:minlen],  toplay[:minlen], 'wb')\n",
    "        stoi_score = stoi( toplay[:minlen], x[:minlen], fs, extended=False)\n",
    "        tot+=1\n",
    "        pesqavg+=score\n",
    "        stoiavg+=stoi_score\n",
    "        print(score, stoi_score)\n",
    "        \n",
    "    #Audio(toplay,rate=16000)\n",
    "\n",
    "print('averages')\n",
    "print(pesqavg/tot, stoiavg/tot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.473032024906034 0.9160656271076375\n"
     ]
    }
   ],
   "source": [
    "print(pesqavg/tot, stoiavg/tot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8qDvy8lEAXfj"
   },
   "outputs": [],
   "source": [
    "pip install pesq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JkPO9Khsji4m"
   },
   "outputs": [],
   "source": [
    "Audio(np.array(lowpassed),rate=16000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LxhpB-eKGOR9"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from scipy.special import kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xpgRGMXnGR8M"
   },
   "outputs": [],
   "source": [
    "# audio1, sr1 = librosa.load('/content/drive/MyDrive/timit-20230118T185105Z-001/timit/dr1-fvmh0/sa1.wav', sr=None)\n",
    "# audio2, sr2 = librosa.load('/content/download.wav', sr=None)\n",
    "# # Preprocess the audio signals\n",
    "# #hop_length = 512  # Choose the hop length for the STFT\n",
    "# #n_fft = 2048  # Choose the FFT window size for the STFT\n",
    "# power1 = np.abs(librosa.stft(audio1, hop_length=hop_length, n_fft=frame_size))**2\n",
    "# power2 = np.abs(librosa.stft(audio2, hop_length=hop_length, n_fft=frame_size))**2\n",
    "# log_power1 = librosa.power_to_db(power1)\n",
    "# log_power2 = librosa.power_to_db(power2)\n",
    "\n",
    "\n",
    "# # Compute the log spectral distance\n",
    "# kl_divs = kl_div(log_power1.T, log_power2.T[:len(log_power1.T)])\n",
    "# log_spectral_distance = np.mean(kl_divs)\n",
    "# print(log_spectral_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "dimaOjwoTgKy"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "sqsTLMTYS0Jm"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEICAYAAABS0fM3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAx20lEQVR4nO3dd3wUdfoH8M9DCB2k9xJUkKKiECkqygkoRcUrenoKlvMQT2ynd6JnPRt3du48xY6KvfzkBMUGgiIlID0gAaJEeu+GkOf3x07CZjO7O7s7dffzfr3Q7Mx3dr6b2cwz3y6qCiIiylxVvM4AERF5i4GAiCjDMRAQEWU4BgIiogzHQEBElOEYCIiIMhwDAaUFEblURD5z4Tz9RKTI6fMQuYmBgAJDRE4XkVkisktEtovItyJyCgCo6kRVPdvj/I0Xkf+Gvc4WkX1RtvX2JpdElTEQUCCISD0AHwP4N4CGAFoBuA/AL17mK8IMAGeGvc4F8BOAMyK2AcB8tzJFFA8DAQVFRwBQ1TdV9bCqHlDVz1R1MQCIyBUi8k1ZYhE5W0RWGqWH/4rI1yJydXhaEXlURHaIyFoRGRx27JUiki8ie0RkjYhcYzGPXwPoLCKNjdd9AbwFoHbEtu9U9ZCIjBGR1cZ5lovIr43zVxeRnSJyfFiemojIARFparw+V0QWGulmiciJSfxOiQAwEFBw/ADgsIhMEJHBItIgWkLjpvsegNsBNAKwEsCpEcl6GdsbA/gXgBdFRIx9mwGcC6AegCsBPCEi3eNlUFWLAPyI0M0eCJUEZgKYFbFthvHzamP7UQiVbl4XkRaq+guADwBcEvb2FwH4WlU3G3l5CcA1xucbD2CSiFSPl0ciMwwEFAiquhvA6QAUwPMAtojIJBFpZpJ8CIBlqvqBqpYAGAdgY0SaH1X1eVU9DGACgBYAmhnnmqyqqzXkawCf4ciNPJ6vAZwhIlUA9AQwG6FgULbtNCMNVPVdVV2vqqWq+jaAVcYxAPAGKgaCPxjbAOBPAMar6hyjdDQBoSoytjtQUhgIKDBUNV9Vr1DV1gCOB9ASwJMmSVsCWBd2nAKI7OmzMWz/fuPHOgBglDhmGw3SOxEKLI1hzQyEnvpPALDGeO9vwrbVBDDHOM+IsOqdncZnKjvPVwBqikgvEWkH4CQAHxr72gG4pew449g2xucmShgDAQWSqq4A8ApCN89IGwC0LnthVPm0NklXiVG98j6ARwE0U9X6AKYAkFjHhZkBoBuAoQiVBABgGUI36qEA5qnqQePm/jyA0QAaGedZWnYeVS0F8A5CpYI/APhYVfcY77cOwIOqWj/sXy1VfdNiHokqYCCgQBCRTiJyi4i0Nl63QegmOdsk+WQAJ4jIBSJSFcB1AJpbPFU1ANUBbAFQYjQiW+6WqqoFADYBuBFGIDBKJHOMbWXtA7URqubaYnyeK1E5qL0B4PcALsWRaiEgFEBGGaUFEZHaIjJUROpazSdROAYCCoo9CDXwzhGRfQgFgKUAbolMqKpbAVyIUCPwNgBdAOTBQldT46n7BoSexncg9DQ+KcG8zgDQBMC3YdtmAmhq7IOqLgfwGIDvEAocJ0Skh6rOAbAPoSqfT8K25yHUTvAfI48FAK4o2y8in4jIHWGv94pIX+PnviKyN8HPQ2lOuDANpTujkbYIwKWqOs3r/BD5DUsElJZE5BwRqW/U+d+BUN27WTUSUcZjIKB01QehfvpbAZwH4AJVPeBtloj8iVVDREQZjiUCIqIMV9XrDCSjcePGmpOT43U2iIgCZf78+VtVtUnk9kAGgpycHOTl5XmdDSKiQBGRH82221I1JCKDjJkeC0RkjMl+EZFxxv7F4RN4GT073hORFcaMj33syBMREVmTciAQkSwATwMYjNDAnUtEpEtEssEAOhj/RgJ4JmzfUwA+VdVOCA3Nz081T0REZJ0dJYKeAApUdY2qFiM0//qwiDTDALxqzOY4G0B9EWlhLDZyBoAXAUBVi1V1pw15IiIii+wIBK0QNtMjQiM4W1lMczRCc628LCLfi8gLIlLbhjwREZFFdgQCs1kZIwcnREtTFUB3AM+o6skIzatSqY0BAERkpIjkiUjeli1bUskvERGFsSMQFCE0xW6Z1gDWW0xTBKDImFwLCK0qZboSlKo+p6q5qprbpEml3k9ERJQkOwLBPAAdRKS9iFQDcDEqz9Y4CcAIo/dQbwC7VHWDqm4EsE5EjjPS9Qew3IY8ERGRRSmPI1DVEhEZDWAqgCwAL6nqMhEZZex/FqGFPYYgNF3ufoTWgS1zPYCJRhBZE7Ev8Lbt/QXzCrdj0PEtvM4KEZGpQM41lJubq0EZUDbsP99gUdEuLLr7bBxVK9vr7BBRBhOR+aqaG7mdcw05bN2O0ISXJaWlHueEiMgcAwERUYZjIPDI/uISzF27HXd8uASlpcGrniOi9BHISeeCZPu+4gqvS0sVB0sOo8vdU8u3De/dDp1b1HM7a0REABgIXPfA5Hy89O3aCtvEbLgdEZFLWDXkkoMlocbi9+avi5OSiMhdDAQuuf6NBV5ngYjIFAOBSxb8tBMAsPtgSaV9a7fsczk3RERHMBD4wLUTWVogIu8wEBARZTgGAiKiDMdAQESU4RgIXHSYI4iJyIcYCFz0769WeZ0FIqJKGAhctPTn3V5ngYioEgYCFwVx7QciSn8MBC76csXmqPsYJIjIKwwEPvHf6au9zgIRZSgGAgcl8pQ/fWX00gIRkZMYCBz0wsy18RMREXmMgcBB3xRs9ToLRERxMRAQEWU4BgIiogzHQEBElOEYCHyCwwiIyCsMBEREGY6BgIgowzEQEBFlOAYCIqIMx0DgILb/ElEQ2BIIRGSQiKwUkQIRGWOyX0RknLF/sYh0j9ifJSLfi8jHduSHiIisSzkQiEgWgKcBDAbQBcAlItIlItlgAB2MfyMBPBOx/0YA+anmhYiIEmdHiaAngAJVXaOqxQDeAjAsIs0wAK9qyGwA9UWkBQCISGsAQwG8YENeiIgoQXYEglYA1oW9LjK2WU3zJIC/ASiNdRIRGSkieSKSt2XLlpQyTERER9gRCMRkW2Q7qWkaETkXwGZVnR/vJKr6nKrmqmpukyZNksmn62b8wIBFRP5nRyAoAtAm7HVrAOstpjkNwPkiUohQldJZIvK6DXkiIiKL7AgE8wB0EJH2IlINwMUAJkWkmQRghNF7qDeAXaq6QVVvV9XWqppjHPeVql5mQ56IiMiiqqm+gaqWiMhoAFMBZAF4SVWXicgoY/+zAKYAGAKgAMB+AFemel4iIrJHyoEAAFR1CkI3+/Btz4b9rACui/Me0wFMtyM/RERkHUcW+wRHIRORVxgIiIgyHAMBEVGGYyAgIspwDARERBmOgcAhG3cd9DoLRL50uFTxyNQV2L6v2OuskIGBwCGvzS70OgtEvjRj1RY8PW017vy/JV5nhQwMBETkqsOHQ52lt+z5Bet3HsDBQ4c9zhExEBCRq7bt+wUAMK9wB04d+xU63fUpg4HHGAgcohwhRmTqtvcrVwl1uutTD3JCZRgIfGjznoPofv/n+GHTHq+zQmSrksMxlx0hjzAQ+NC9k5Zh+75ivPxtoddZIbLVrNXbvM4CmWAgcEgqNUNTlmy0LR/kH6u37MXHiyOX6sgssf4urp6Q51o+qCIGAod8vnxTQunn/7ij0rY35/6EZ6avtitLGa/TXZ/gic9/8OTcB4oPo/9jX2P0G997cv4g+CI/sb8Zsg8DgUMKNu9N6rjS0orPTP/8dIUd2SEABw+V4qkvV2HKkg2un/uWdxe6fk4iqxgIfOYwuxs57v35Ra6fM7y6b9veX1w/P1EsDAREDisuqdhTpscDX0AzNOCL1xkgUwwElHG+XLHZ1fM98UXldonX5/zkah6IYmEg8JnZa9i9zk6qipwxk/H8jDUVts8q2OpaHuau3V5pW9H2/a6dnygeBgKbzV6zDTljJid9/L2TltmYGyrz4JT8Cq+Ldh5w7dxmPcKI/ISBwGYXPzc7peNXb9lnU07Iz8ZHlFAyhcRpJFjwE4OmFxgIKK0V7Yjy5O9SW+2m3VyXItw8k2qycG+43Hby884DyBkzGff9L7NL4gwEAZCpPUzscO3E+abb8zfuduX8sQZJrXApD34y7qsCr7NQweuzfwQAvPxtIfI3ZN71KMNAEACccyh5kV03y7j1O10bo6pv0JMzXckDRRc+cv/fX63yMCfeYiAIgCU/7/I6C4HlZWFqx75ivPDNWu8yEEBu9ZrLK9yOE+6d6sq5goCBgNJarDhwyOEpkff+UhI3TeSUIpkuapuOzR79bCX2HKx4faYs2Yinp/mr6sotDAQBwDaC5MWa86nU4d+rlbdfuWkPrp4wD78f/52jeSFrHpm6Mul5woKMgYAy1mGHn8bVQtekwU/NxBf5mzFn7XYsXLfT0fzQEbPXRO+9NODxr13MiT8wEFBcO/YVezJRm9MenJwfP1EK7v84sff/itMwA4jewG+H0lLFrv2HHHv/oLIlEIjIIBFZKSIFIjLGZL+IyDhj/2IR6W5sbyMi00QkX0SWiciNduQn3WzeYz5b5fqdBzBz1RbHz3/9m9/jlncXoXBrsAa7/VISe0H0rxycc0hVOb9+kp40mZvJLk9PK0C3f3wWN13QvuupSjkQiEgWgKcBDAbQBcAlItIlItlgAB2MfyMBPGNsLwFwi6p2BtAbwHUmxwbGCzOdGS06a/U204bNQU/OwPAX5zpyznBlg6K27SvGmi178fK3azFpkXcrba3cuAc5YyZj8FOxu1+6PTgp3KUvzEn8oHjDbjPERgcH4U1dbm31v36PTkfff33lWD78pqoN79ETQIGqrgEAEXkLwDAAy8PSDAPwqoZaPWeLSH0RaaGqGwBsAABV3SMi+QBaRRwbGGWDU5zwZf5mDDq+eYVtuw/G75Vip98+M6vC6w5N62DwUzNxTtdmuHlgRyz8aScu7tnW8XxMXxl6ks/fsBvrtu9Hm4a1TNOVHI5dR+9kW7Gda/PuLy5B9apZyKqSIYHCJ30j1m13bz4qr9lRNdQKwLqw10XGtoTSiEgOgJMBmD5KichIEckTkbwtW5yvDvGbeNUciSgtVfzp1TzMidNne39xCc56bDpWRelFcfPbCwEAU5dtwqAnZ2LMB0tsy6NVW2Ms8hKvsdZKY66bolXzdbl7Kv723mKXc2O/zRaf9D/4/meHc2Kd012M/cKOQGD2mBL5FxYzjYjUAfA+gJtU1XSct6o+p6q5qprbpEmTpDMbVDe+tdC299qxvxifL9+EaycuiJnu3bwirIkxMnbFxj225SkRD39ibfnOVwI2Ivv7n3ZG3ff+guA31pcEcMzE3R8tNR3rUVoamt78cY/WwLabHYGgCECbsNetAURWIEdNIyLZCAWBiar6gQ35cczf3luEnDGTUbQj2HPJW/lzPFyqmJzE2r5u/27WRRmAtOfgIazf5c2EbyUpPEV+/UPmlXbdtPTnxOYTenPuOtP5qsqWlP1vmgxAsyMQzAPQQUTai0g1ABcDmBSRZhKAEUbvod4AdqnqBhERAC8CyFfVx23Ii6PeyQs9lZ3+z2mm+wu3BSNAlNWNx6pxHv3GAtMFVeKJ9rtxyg1vfm+6PV77AAD84lA3xT9OyEv62I8WRq8WcXrcA5mbumwTduwr9jobjko5EKhqCYDRAKYCyAfwjqouE5FRIjLKSDYFwBoABQCeB/BnY/tpAIYDOEtEFhr/hqSaJzcUbPamWsRO0Tqp3Pz2Qnyy1FrvCjOJjoR+4OPluPJl53s/RdrpUH/yVJ7qP1hQMRA8HLagjhtdhcncvELzh6J0Cc129BqCqk5B6GYfvu3ZsJ8VwHUmx32DgKxnffBQxcbaH7ftx7FN63qUm9TEayT9MMXGujfm/oRLe7WznD6Ridn2WZi/J52EL2BzxcvzUDh2qIe5cc9nyzbi7K7N4yf0SCBuWgngyGKL3s1bV+H1rgPejk7csMuOrm3OfJ3/z8FeH2a9hLZEGXAXVN8ZXU+dHGHrd58t99dgvJGvzS8v6aoqnnBw0JsXGAgsiqyf/cs7izzKSUhKc9nHKBD8uC14IyrvNVld6sCh5Lrbzlq91fPfwR8nzAMA3O5Bd1wnBX283NvzQg+DC37agaenhdYxSJcJIRkILJI43+JpK1OfrmDW6q2W06ZSIin76pp9pN8+k/osmPMKnVt3VkxKMWbd+5Ltd/+H5+fgzEemJ3WsXfYXh4KYWZfRnfuLbR1T4paiHfsDX3KbWRD6+0zHoQW2tBFkgvFfr465P7LqKBk79rlb3WQW2nbu9653xJ6Dh1C3RnbMNDe/s7DSNrNRvEFfzCdnzGTT7Sf943P0at8Qb1/Tx+Ucpcbt3mROyd+wGxel4ZThDAQWmfVJP1yq5cP+7bjxuDXStaw0azaZnV05UNW4pahIm3YfjBsI5v9YubThdXuN2+as3Y6iHfvRoFY1ZGdVQbWqLNi7YfLiDViUplOF8xuUgpVhI2uDNC9JeMCZFjEDp1191Ue85H530HDJBId124MxDgQIPWF3vWcqej/8Ja6buKBSrzZyhlsrqLmNgSBF01ZsxqwC63X7fuPUSOCZq+z/nSwpcra6p++/gld9sX1fMSYv2YAZHJEc10aPRpoHAQNBCmat3oorX5mHPyQz5bCHwjs6OFkZlfhTauyqpHdsaIex6uPF3k2zTcB7DiyEdONb5qPQU5EefYYYCFLygMMrXCVjxg9b4s51E/7ldbL3W6e7PsXsODOcJiJWk4PdXT5Hv2H/TSMIBj05AzljJpu2xfhVaali1Gvz8dHCn2NW7x3M4HEZ8TAQpJGXv12LES/NxVNfrvI6K+US6Qsfr2051u5kq0ZuS4PpnYHQgKd5hdsxZcmGmPMVPTQlHxNmFUbdXzajbOTaE36xa/8h7DlYsf3nsc9X4tNlG3HjWwtjV++lSZ9/JzAQWBCU/s/3/S+0ns/0lbFviuGDYJweELN2676Ez7Fp90HkjJlcaYTyXAfGJ7ztYnWT0y589jv8eeIC3PjWwqgjz5+bsQb3TFpma0nNTd3+8RlOvK/iUpNWq5EWO9ClOF1iCwOBBWsDtn5pvK6s4V/ee//n/GJwVkdBv2TMOfTDptBT6bvzK96k8zdEn0I4mSmz01mfh79CzpjJUReDufi52bh30jIs/XkXZq7aYlqlYrWUNf/HHdhf7N4cUOHf3593HsCm3RUf1LZFWazIqZu2050Y3MBAYIFfhsYnMs+9m3+Y8azcZG2m1onGGsNlJbDwueP3xplsbvaaxKfMzgS3vBt9KpRXZhXi3H9/g+EvzsWZj0zDsxGDJq10Ad669xf89plZ+Mvb7k+5UlqqOG1s5XWFr3xlnqv5OO8/37h6PicwEFjgVhyI98SSyERXa7fuww+b9gRuoZODhw7jIWPq5V0HDpVPMrfJwQXN05nVietKFRhrsvKbWbVecUkp7p20DNv3FWPb3tBI9KXr3X8qjjZL7uI0eEJ3G0cWB0isZSMj/2CHjjvylDKgczO8cHmuY/myYsqSDRhyQou46S57YQ627j0yzUXuA1+gcOxQS8H4m1VbUSO7SswqJErM63N+wvDeFacU/2TpBrwyqxC7DxzCaqPa9OedR9ok1m7dh7zC7bgwtw2clGkjyp3EEoEFblUNzVkbuwEvVokhVh/7L/I3lU9tbOaZ6bHnUbLDSovrG+dF6bZoZbqKy16cg989+x3u+qjybKSZKl6VWjzLTZ70y76Ha7buK59yQRX41FjMaOi4mfirDb2x4q2QF+sr8cLMNdF3UiUMBJa4Ewlen/1T0sfGWvgcAC55fnb5z5EB5Z+fWlsMPhVB7FyxeU/wq6OWrU+tdBQrAC+MmHdn1Ovzcf/Hy8tnT03VReO/Q2GMjhobY1QXRi4qH8QZW93EQGCBXxqLY01K99a8+N0gy1b3cmtyu3DjvlyFf6cwvsGLSzDixblpMYdPKtOIZJl8+WP9PbyYwGpzVvR7dHrUfeO/jv7UH5nFyMBAFTEQZBCzxsAyQ55KYaEbix77/AfkjJkcmEXYV2zcg9/8158DqxJx+j+n4ePF62NWD0YzZckG5IyZjO9/OlJlZ7UbppfXeV9EqSQoY4G8wkBgwWvf/eh1FgCk3g96tzEi0+x9lrvYwPryt4k9Ne7YV+xoqSxWPXqivxe/NmCOfuP7CtWDVm3bF2q4v+a1+QkfO3GOP/5uvFZyuBRfrfDX0puRGAgsSHUxd7uk+nxV9lTk9fN4onM0laqarkxmlzHvx27YfHpageX3uuejpalmx5c27/kFw57+FoD1qtINNs32mWxwXb1lry3nT9W4rwpw1St5vu7KzUCQQcpW8vLDOquR88XE4nQNQ3jXRzOPTF1ZadvO/cU44d6pmP9jxZ4tuw/6ZyCf3Rat2xl15TQzdvVG63bfZ5W+s1ZGPQ9OZV1vG5VNiPjNKgYCskG0+/fuBG6qgPclAgDlg8asyN+w2zcN9mVmrtqKPQdLTINEuvPiOWLSoorTgluZbbbYxcWFzdbNVlUUbN6DjxaG8v78THsb0u3EQBAgX+Sb1zMuTXAkZbQSgZuLm7w51/pkb06vdpZojJm1eiuufzM0TfXsNdvL+88D/ihtOc2Luv/I+b6slrw+WbLB9CZtN7Og889PV2LA4zMcP7cdGAjSQCIL40SbhAzwfnlJryS6tvJNby2s8HrU6/PLRzOnfxgA5jkwC2w8T35RsetxrPEF4a6duABH3zEFHyxwtp1vx/7iSl2NI+duAoCcMZNx7B1THM1LMhgIMsxHC9f7ZurcRKZC9tP8MZtNuiLu/aUEG3cdTItxB0GwY7+/emf1efgrdLrrU0tTYpf4sPs0A0GGqV8r2zdPrYm0E1z3xgLH8mFlYrbnZ8SesmDjroPo/fCXnAXVQeFrg0erJvXarcZsr4m223mNgSDD/PW9xdjqk8E1i4t2Yce+4vgJHRZv/QYAeDBO0CprM6CK7Gwz+bODDwN2mr5yM06897OYaS7z2TrnDAQB882qrfETxZFIm4LTYo12puBbZGOV3k6fVQdFc8XL8ddD+KZga0JdcZ1mSyAQkUEislJECkRkjMl+EZFxxv7FItLd6rF2UtXy+XascqPHQSJWbEyvKZb9slTkJ1zhzBEPJ1D9l4lyxkxGzpjJeHDycix1YClNq1Jej0BEsgA8DWAggCIA80RkkqqGr4E4GEAH418vAM8A6GXxWNvc8eESvDl3HZ4fkYufd+zHMU3rYMf+Q7jhze9x1WntceZxTbBzfzHmrt1evlqW3zwwOR/fR8z6SKm7dmL8aoecMZPx9yGdXchN+pizdjuWebBoTdA8P3OtpXEG1atWwcoHBtt+fkm1Dk9E+gC4V1XPMV7fDgCq+nBYmvEApqvqm8brlQD6AciJd6yZ3NxczcvLSzivfiqKERElY9hJLfHUxScndayIzFfVSqtU2VE11ApAePm+yNhmJY2VYwEAIjJSRPJEJG/LluQGPo0f3iOp44iI/OLq04+2/T3tWKrSbDROZDEjWhorx4Y2qj4H4DkgVCJIJINlzunaHIVjhyZ0zObdB9HzoS+TOZ1j1j48BO1v99+glHT3l4EdMfj45hj4RDBGi/pBtawq+OHBwSyNJ+GHBwajWtUq2F9cgpJSRb0a2Y6dy45AUAQgfHHS1gDWW0xTzcKxnmpar4bXWahg3t8HJDwSNlLtalmV5mv3yp1DOyc8G6kTZt/eH70fjh3wb+jfwaXcpI/Xr+7ldRZ8L97Daa1qzi8tb0fV0DwAHUSkvYhUA3AxgEkRaSYBGGH0HuoNYJeqbrB4LIVpUrd6yu8x784BNuTEHn88vb3XWQAAND/KXwE/XRzbtI7XWfC1RGsonJJyIFDVEgCjAUwFkA/gHVVdJiKjRGSUkWwKgDUACgA8D+DPsY5NNU+ZoEZ28pfOybn9E/HqVT1TLt24pVub+l5nIZAa1q5m23sVPGh/bxkvzf17f6+zUM6WMoeqTkHoZh++7dmwnxXAdVaPJeeMPMP+hqZkXNijNc7o2MRy+st6t8Xrs73r0vv2yN4x90++4XRUrVIF5zyZ/u0HXlQtrn14SIWHhlOPaVS+voZf1MzOwlE1s/HR6NOw68AhnB2jLckvJYEyHFlswVmdmnqdBdvcNqiTJ4vXR7rn/K4Jpe/YrK5DObGmRnZW1H0rHxiEri2PwnHNvc1jLDmNamHOHfY8gT7x+5NseZ9ERJYc3/hT7MDstmX3nYP8+wdh9h390axeDXRsVhf3D0vsO+4l51sh0sBXKzZ7nQUAFasnwod//PDAYHS88xNL75FVxfuqmOdH5KJOdetfvevPOhZVHKxCuuq01NopqleNHiS8Nn54D3RoWgdHN7Gvrr6ug71XzLxzTR9Xz5eM2ibf59OObWyadtwlyY0BcBJLBBb4pTrlzASqUpJxfreWjr4/ANw/rCsGdmmW0DE39u/g6AplvY9uGHN/6wY1K7xuZGO9t5PO6tQU53RtbmsQWHLv2a6XKNs1qpXyeyy4a6ANOUlMtN+7G39niWIgsGBEn3ZeZwFAxUEXkX+Kjeuk3pvo9iGdUn6PWDo0rYPhfXISPk5EHC0RnN21ecz9l/RsW+H17BhVLM9e5v2gxeeG90Dh2KF46YpTUn6vvwzsiMKxQ8v/uV0auG1QJzQL68L9zKXd8W/jibpV/ZrRDkOXFvXQyaiqG3fJyahXw5vKjxX3D/LkvIli1ZAFrRuk/kRih9rVzasgRIAsCyH9vDhPIjVj1IOnavzwHuifQluLl4t5XBNRIsyO8cvu1uYop7Nj6pyuzTB+eKWZA1J2egfz6g23XNvvmAqvB5/QovzniVf3Qr9Hp1c65vxuLfH4Rd2QVUWwcN1OnNSmvmeLMdXIzsL53Vpi0qL1ePTCbvjNyaYTJ3iOJQIfadMw+hNOJRFf7MMWbpQPXHB8zP31azlX5VGnelVUtRKtTAiAoWE3ALeZ5TtaQ2CLoxK4hjZ65lJrJZFPb+qLjs2sVxV1b9ug8kaXbqprHhoSc39O49qVtg3o3AzjLjkZVbOqQERwctsGEBFHqxbjOd1oK+jcoi6q+KCNzgwDgY/EG0Ie7alGAGzdG3uBl9f+2BNH1XS3WB+uV/vY9fDRdG5RD1WqiKX+6HZUj1l1VudQO8ek0ae5ds5YrN5gOjWvF/X3tCqin/6Dv4794BDP+9em1sibzE1zzGDz6k0RsaX3379+d2LCx1yY2xrz7xyAri29KS1awUDgI/GemLXCzxWjQqz60vHDe6Bvh9gNzT2TvFFbMe3WfkmXBm60OK3Db7u3Rt6dA/CHXm3jJ07ANWeadxRoVb8mCscOxYmt69t6PgAYFKfNItLie89OKL3Z03EVqVjl9fhF3XBpL/O2scjnkTuitC31aOfcd6rM1JvOKP/53BNbxBzJ3MyG6WIGH98cxzSpXBKJRUTQyMWHlGQwENjgxcvtqZutUTVOIFDznwHg4lPaIJpzIm4sZiWLV65MvWHRTOHYoWhvUoRPRp+jG0XdV3bDfujXJ9hyLiBUGrl9sHvrD4zo0w4FDw7Gs8N7JBTQEp2MzGxkeeRX4jfdW0c9vqrxpH5cs7p46YpcjDzjGMsB26oLTrLWs+a45nVROHYoHr2wGx7+jX3XPpq6NbLx3qhTHT+P2xgIUtC1ZT0Ujh2K/p2blfdkSMXxrWIXHaPd7EUEI6L0xolsbIumbGKrWAElUV/ecmbK73HqsUdu/rHqecN3Lbzbnq6Cdq63a8U/hh1fXnJ66Ncn4PsYXR6vP+tYAEB2VuLVJ2a/x+pxHkLC9WzfEH895zi8ObI3zuoUqiK7eWBHfHJjX8y1adDabVGqeKL5XY/WcXs03dD/2FSyhOdHmD/wxRt1HgTsNZSC+8MaX+2of+x9dCO8+E30VYoaJNF//ZaBHRNK37lFvYTPEWnh3QNRrWqVlGdNjByGHysQhDd0O9no7RSzevtY1/umAR1xxak5SVW53TSgA5av341t+0LtSncM6YQzO4a+vx/8+dS4vcdEBNf9qvJN1Y7vDuDc9AupNuRHG//SK0ZJNShYIkiBaY+KFCQy0Cr8WVXK/1PRF385I+EbRap/zBOu6on6taqlFASm3doPs2+v/GTZI8bv245ZWSPFmlYilkX3JFZnDwBTb+prut2sPrpw7FBkVQnVOyfTAaBHu4aYH1baGHnGMeXTY3Rv28C2G3oyerSz92+KrGEgsEmtau5OMxCv2uKNP/XCsU2tzX1zWlj1S6KNxu+OOtIzpODBwSmPfu5zdCO0b1zbdFroGwdYL91cbXF66/tjdKn976XdLZ8vXCI35wtOaonpt/aL2pgYGVBfusK+sQJvj+yNmX/7lW3vZwezqRr8ILwBv36tbAzv7Y9BpnZhILAosuj+3qiKXePcnk65f+fYpYdTj7E+EOj1Pya3eEiDWtnIbdcAU286A89c2j3pnkFlTju2ER7/fbeo+xOZJym8bSGWWH/QLWP0xLLLkxefbNofPho7Bzf2OroR2jT0x2DJMg1qedfFOZYzjzvygCMiMR8ggoiBwKKzOlV80m3XyJ6eMMkKb5wWCU0NbFVkzIoMYtG6A4af+44hnfD93WdDRHBc87oVRnwm6/bBnZOqx+3r8ejXZP31nOPiponsJtzE590QgdD3J9kSsl9vsMfYOF+THzEQWOS3ImuN7CzkhtWnhj+Nn3qM9cYrs5v+yDOi9zQa2KUZzuvWMmYat71mUqLxy+I7sVxmoXrh2IgbUDIdBtw28oxjsPwfyc2x4+S6vECod1EynBxn4wcMBBZZeXp79aqeLuTkiJevPAUfX396pSf6Xx0XuwdTePNCtAFRy+47p/znstJHj3YNonaho4qs3HCstCU8FNY3/kkP1gGwy/9Gn45PbjRvEHfTuSd6N1WJnzEQWFSrWtW4g3yS7WWSrLo1siuMPZhzR3/0bN8Qv03gqad3lK5vtatXxVmdmuKUnAY4r1tLLLr7bLx/bXAG0hwVp6756Ca1Mf3Wfqb77j63S8pz4MebEsPqdBi1qlXFnUM7o26Nqhh0fGIjjv3khNZHedobqUy/45qicOzQhDo1vBljEZyArLQal7/qO3zu7nO7oGvLeti8+xc0ruNuET3aVAfhmtWrkdANLF49bvg0xvFurHaw8ke16J6z0e2+z8pfRyuyx+vaO/n6vqgZ5fNfZbHHUSxV4zRs92xvvZvk1X2PxtV9/bEmRrqob/H7fH63lugTpar15StPwTGN06PtgCWCBNTIzsKlvdrh5oEdTXsJOdkH+taz41dNBVUiT4qR1SmxejxFG/F5VM3sqEHALmYDrsK5OXUFVRav112ZRy6MPsncr45rirY2LJrjBwwENnJqGchTchrEnAM/6JKdyqF5vRqoFmNqhGgjPs0GqwHAlafloJpNv+d4nQv81m0z05zfrSXyLTRo+3kZUjuxaigA3k3DSa7MWO3ps/bhISjacSDp2SSjlQbuOa8r7jnPvgXHc9s1QN6POyptb+rAKGhKnNOlwiBJ38dMj6TadhBtPvV0VlYH26C2tXpbEUGbhrVilgaOpK342s11QZ4dbr5YTKsG3ixeQ4m5c2jmVN8xEPjMqDMr9s+Pt6pYOrhjSGdMu7WfI6t7fXvbWXhhRC7uPa8LAKCei4vzRFvknl1w/e+KU3PwRxs6DQQFq4Z8aPzwHjimSW3LcwUlyrvVf81lZ1Wxbc2CSC3r10TL+jVRWqpYVLQLI/p4P0dMwwDOjuqGfselNk9VMu4+twv+8fHyStu7tKzn+rQxXmIg8KHIhWSckjlf89Cyh0/4ZECWX9etdcNpxzbCtwXbTPe9cqW7AzJj8esi805h1ZDNXF7LhHwsk54orXrswpO8zkJcDWtXS3kCxaBhiYDIRek2fXGi/FYYqhqxwtsrV56S0My96SKzwp4L0mWACdnjvvOPdEcd/atjfTu7ptvcHpkfzUW5bfBbY33m4b3bod9xTS31Rks3KX1iEWkoIp+LyCrj/6ZDa0VkkIisFJECERkTtv0REVkhIotF5EMRqZ9KfvyAPUIo3OWn5pQHg0RWoEt3IoK3fLDWb43sLDx2UTcUjh2a0UE61dA3BsCXqtoBwJfG6wpEJAvA0wAGA+gC4BIR6WLs/hzA8ap6IoAfANyeYn4814A9QijC5afmoHDsUHRrU9/rrPhKtO615L5UA8EwABOMnycAuMAkTU8ABaq6RlWLAbxlHAdV/UxVS4x0swEkN1k4JaSsVjQ7A4vA5B8dmtXFh38+FR2bpcfEbUGWamNxM1XdAACqukFEzCbCbwVgXdjrIgBmM4VdBeDtaCcSkZEARgJA27axp4P2ks/awkzVrl4VfxnYEYMDPK0xBZTxB1I2p9PJbRvg4+v74nApu9t5KW4gEJEvAJjdMf5u8Rxm98YKV11E/g6gBMDEaG+iqs8BeA4AcnNzffutSbaPuFMT1kVzQ/8Orp6PCAgttXnzgI44/6SW5dsysXHWb+IGAlUdEG2fiGwSkRZGaaAFgM0myYoAtAl73RrA+rD3uBzAuQD6a7LTUBJRIIgIbhzAhxC/STUUTwJwufHz5QA+MkkzD0AHEWkvItUAXGwcBxEZBOA2AOer6v4U8+Ibpx+beD9kxkAi8kqqgWAsgIEisgrAQOM1RKSliEwBAKMxeDSAqQDyAbyjqsuM4/8DoC6Az0VkoYg8m2J+fMHK+sZERH6RUmOxqm4DUGmVD1VdD2BI2OspAKaYpIu9jFMG4XQEROQVttIQEWU4BgIHdGC/aCIKEAYCB9Sqxrn8iCg4GAiIiDIcA4FPlLL7KBF5hIHAIX6ZZpeIKB4GAofcPLBjQunZeZSIvMJAQESU4RgIiIgyHAMBEVGGYyAgIspwDAQ+wc6jROQVBgKf4DACIvIKA4GHuJg5EfkBA4GHjm5cG9lZoREEvdo39Dg3RJSpGAg89OCvj0fN7CwAwLhLTvY4N0SUqRgIPBQ+S2mNqlke5oSIMhkDgUOObmxtTYLHLjoJnVvUQ50anLqaiLzBu49D+hzTyFK6gV2aYWCXZg7nhogoOpYIiIgyHAMBEVGGYyAgIspwDARERBmOgYCIKMMxEHjksQu7eZ0FIiIADASe4TxDROQXDARERBmOgcAjwtXqicgnGAgc1Kl5Xa+zQEQUV0qBQEQaisjnIrLK+H+DKOkGichKESkQkTEm+28VERWRxqnkx29ObH2U11kgIoor1RLBGABfqmoHAF8arysQkSwATwMYDKALgEtEpEvY/jYABgL4KcW8EBFRElINBMMATDB+ngDgApM0PQEUqOoaVS0G8JZxXJknAPwNXLaXiMgTqQaCZqq6AQCM/zc1SdMKwLqw10XGNojI+QB+VtVF8U4kIiNFJE9E8rZs2ZJitt0hYIswEflf3EAgIl+IyFKTf8PiHVv2FibbVERqAfg7gLutvImqPqequaqa26RJE4un9o9fn9zK6ywQEZmKux6Bqg6Itk9ENolIC1XdICItAGw2SVYEoE3Y69YA1gM4BkB7AIsk1JeyNYAFItJTVTcm8BkC4dwTW+DD738uf928Xg0Pc0NEdESqVUOTAFxu/Hw5gI9M0swD0EFE2otINQAXA5ikqktUtamq5qhqDkIBo3s6BgEAaH5UxRt/7epcE4iI/CHVQDAWwEARWYVQz5+xACAiLUVkCgCoagmA0QCmAsgH8I6qLkvxvIHAQWNEFAQpPZaq6jYA/U22rwcwJOz1FABT4rxXTip5ISKi5HBksUsEgkt6tvU6G0RElTAQOKh7W9OB1kREvsJA4KALc1t7nQUiorgYCBwkEa3FfTuk1VRKRJQm2IfRJW0b1UKXlvW8zgYRUSUsEbikDscNEJFP8e7ksMcv6oYWR9Usfz3hqp5oWre6hzkiIqqIgcBhv+lescH4zI7BmyeJiNIbq4aIiDIcAwERUYZjICAiynAMBEREGY6BgIgowzEQEBFlOAYCIqIMx0BARJThRFW9zkPCRGQLgB+TPLwxgK02ZsdL6fJZ+Dn8J10+Cz9HRe1UtdKo1kAGglSISJ6q5nqdDzuky2fh5/CfdPks/BzWsGqIiCjDMRAQEWW4TAwEz3mdARuly2fh5/CfdPks/BwWZFwbARERVZSJJQIiIgrDQEBElOHSNhCIyCARWSkiBSIyxmS/iMg4Y/9iEenuRT7jsfA5+onILhFZaPy724t8xiMiL4nIZhFZGmV/UK5HvM8RlOvRRkSmiUi+iCwTkRtN0gTlmlj5LL6/LiJSQ0Tmisgi43PcZ5LGmWuiqmn3D0AWgNUAjgZQDcAiAF0i0gwB8AkAAdAbwByv853k5+gH4GOv82rhs5wBoDuApVH2+/56WPwcQbkeLQB0N36uC+CHIP6NJPBZfH9djN9zHePnbABzAPR245qka4mgJ4ACVV2jqsUA3gIwLCLNMACvashsAPVFpIXbGY3DyucIBFWdAWB7jCRBuB5WPkcgqOoGVV1g/LwHQD6AVhHJgnJNrHwW3zN+z3uNl9nGv8jePI5ck3QNBK0ArAt7XYTKXwwrabxmNY99jOLkJyLS1Z2s2S4I18OqQF0PEckBcDJCT6DhAndNYnwWIADXRUSyRGQhgM0APldVV65Jui5eLybbIiOrlTRes5LHBQjNH7JXRIYA+D8AHZzOmAOCcD2sCNT1EJE6AN4HcJOq7o7cbXKIb69JnM8SiOuiqocBnCQi9QF8KCLHq2p4e5Qj1yRdSwRFANqEvW4NYH0SabwWN4+qurusOKmqUwBki0hj97JomyBcj7iCdD1EJBuhG+dEVf3AJElgrkm8zxKk6wIAqroTwHQAgyJ2OXJN0jUQzAPQQUTai0g1ABcDmBSRZhKAEUYrfG8Au1R1g9sZjSPu5xCR5iIixs89Ebqm21zPaeqCcD3iCsr1MPL4IoB8VX08SrJAXBMrnyUI10VEmhglAYhITQADAKyISObINUnLqiFVLRGR0QCmItTz5iVVXSYio4z9zwKYglALfAGA/QCu9Cq/0Vj8HL8DcK2IlAA4AOBiNboX+ImIvIlQz43GIlIE4B6EGsMCcz0AS58jENcDwGkAhgNYYtRJA8AdANoCwbomsPZZgnBdWgCYICJZCAWqd1T1YzfuW5xigogow6Vr1RAREVnEQEBElOEYCIiIMhwDARFRhmMgICLKcAwEREQZjoGAiCjD/T8E3SRgzutLAwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Time = np.linspace(0, len(data) / fs, num=len(data))\n",
    "t = np.linspace(0, len(toplay) / fs, num=len(toplay))\n",
    "toplay=toplay[:Time.shape[0]]\n",
    "plt.figure(1)\n",
    "plt.title(\"Signal Wave...\")\n",
    "plt.plot(Time, data)\n",
    "\n",
    "plt.figure(2)\n",
    "plt.title(\"low passed\")\n",
    "plt.plot(Time, lowpassed[:len(Time)])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(3)\n",
    "plt.title(\"predicted Signal Wave...\")\n",
    "plt.plot(Time, toplay)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4cHVXbGKTvLd"
   },
   "outputs": [],
   "source": [
    "print(toplay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JPnIwJhvUwmb"
   },
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VunbnVSiU7Ec"
   },
   "outputs": [],
   "source": [
    "Audio(data,rate=16000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S2EofDTCVE8r"
   },
   "outputs": [],
   "source": [
    "print(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cH1zuMlJc1Uu"
   },
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WIqB99s8crKY"
   },
   "outputs": [],
   "source": [
    "def smooth(x,window_len=11,window='hanning'):\n",
    "    \"\"\"smooth the data using a window with requested size.\n",
    "    \n",
    "    This method is based on the convolution of a scaled window with the signal.\n",
    "    The signal is prepared by introducing reflected copies of the signal \n",
    "    (with the window size) in both ends so that transient parts are minimized\n",
    "    in the begining and end part of the output signal.\n",
    "    \n",
    "    input:\n",
    "        x: the input signal \n",
    "        window_len: the dimension of the smoothing window; should be an odd integer\n",
    "        window: the type of window from 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\n",
    "            flat window will produce a moving average smoothing.\n",
    "\n",
    "    output:\n",
    "        the smoothed signal\n",
    "        \n",
    "    example:\n",
    "\n",
    "    t=linspace(-2,2,0.1)\n",
    "    x=sin(t)+randn(len(t))*0.1\n",
    "    y=smooth(x)\n",
    "    \n",
    "    see also: \n",
    "    \n",
    "    numpy.hanning, numpy.hamming, numpy.bartlett, numpy.blackman, numpy.convolve\n",
    "    scipy.signal.lfilter\n",
    " \n",
    "    TODO: the window parameter could be the window itself if an array instead of a string\n",
    "    NOTE: length(output) != length(input), to correct this: return y[(window_len/2-1):-(window_len/2)] instead of just y.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    if window_len<3:\n",
    "        return x\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "    s=numpy.r_[x[window_len-1:0:-1],x,x[-2:-window_len-1:-1]]\n",
    "    #print(len(s))\n",
    "    if window == 'flat': #moving average\n",
    "        w=numpy.ones(window_len,'d')\n",
    "    else:\n",
    "        w=eval('numpy.'+window+'(window_len)')\n",
    "\n",
    "    y=numpy.convolve(w/w.sum(),s,mode='valid')\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bpa3fMjDc4Ti"
   },
   "outputs": [],
   "source": [
    "toplay=np.array(smooth(toplay))\n",
    "Audio(toplay,rate=16000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "euVejETfdMRN"
   },
   "outputs": [],
   "source": [
    "Time = np.linspace(0, len(data) / fs, num=len(data))\n",
    "t = np.linspace(0, len(toplay) / fs, num=len(toplay))\n",
    "#toplay=toplay[:Time.shape[0]]\n",
    "plt.figure(1)\n",
    "plt.title(\"Signal Wave...\")\n",
    "plt.plot(Time, data)\n",
    "\n",
    "\n",
    "plt.figure(2)\n",
    "plt.title(\"predicted Signal Wave...\")\n",
    "plt.plot(Time, toplay[:len(Time)])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
